{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed889c9",
   "metadata": {},
   "source": [
    "#### 虐待分類と口腔内状況の関連に関する学術論文用解析コード\n",
    "##### Analysis of Oral Health Conditions by Child Abuse Type\n",
    "\n",
    "研究対象: 一時保護所に保護された児童（虐待4分類）\n",
    "- Physical Abuse: 646人\n",
    "- Neglect: 328人\n",
    "- Emotional Abuse: 201人\n",
    "- Sexual Abuse: 60人\n",
    "\n",
    "論文構成:\n",
    "1. 対象者の基本特性 (Table 1)\n",
    "2. 虐待分類別の口腔内状況 (Table 2)\n",
    "3. 統計解析結果 (Table 3)\n",
    "4. 多変量解析 (Table 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2eb93",
   "metadata": {},
   "source": [
    "### ライブラリのインポートと初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, kruskal, mannwhitneyu, spearmanr\n",
    "from scipy.special import comb\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# タイムスタンプ\n",
    "timestamp = datetime.now().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b57406",
   "metadata": {},
   "source": [
    "#### データの入力・出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7ea2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '/Users/ayo/Desktop/_GSAIS_/Research/OralHealth_tokyo/paper_analysis/data'\n",
    "OUTPUT_DIR = f'/Users/ayo/Desktop/_GSAIS_/Research/OralHealth_tokyo/paper_analysis/result/{timestamp}/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d35a5a",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a120e2",
   "metadata": {},
   "source": [
    "#### （廃棄）カスタム統計関数（scikit-posthocs/statsmodelsの代替）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ef29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posthoc_dunn(df, val_col, group_col, p_adjust='bonferroni'):\n",
    "    \"\"\"\n",
    "    Dunn's post-hoc test の簡易実装\n",
    "    Returns matrices for both adjusted and unadjusted p-values if requested\n",
    "    \"\"\"\n",
    "    groups = df[group_col].unique()\n",
    "    n_groups = len(groups)\n",
    "    n_comparisons = comb(n_groups, 2, exact=True)\n",
    "    \n",
    "    df_work = df[[val_col, group_col]].dropna().copy()\n",
    "    df_work['rank'] = df_work[val_col].rank()\n",
    "    \n",
    "    group_ranks = df_work.groupby(group_col)['rank'].agg(['mean', 'count'])\n",
    "    N = len(df_work)\n",
    "    \n",
    "    p_matrix_adj = pd.DataFrame(index=groups, columns=groups, dtype=float)\n",
    "    p_matrix_unadj = pd.DataFrame(index=groups, columns=groups, dtype=float)\n",
    "    \n",
    "    for i, g1 in enumerate(groups):\n",
    "        for j, g2 in enumerate(groups):\n",
    "            if i == j:\n",
    "                p_matrix_adj.loc[g1, g2] = 1.0\n",
    "                p_matrix_unadj.loc[g1, g2] = 1.0\n",
    "            elif i < j:\n",
    "                n1 = group_ranks.loc[g1, 'count']\n",
    "                n2 = group_ranks.loc[g2, 'count']\n",
    "                r1 = group_ranks.loc[g1, 'mean']\n",
    "                r2 = group_ranks.loc[g2, 'mean']\n",
    "                \n",
    "                se = np.sqrt((N * (N + 1) / 12) * (1/n1 + 1/n2))\n",
    "                z = abs(r1 - r2) / se\n",
    "                p_unadj = 2 * (1 - stats.norm.cdf(z))\n",
    "                \n",
    "                p_adj = p_unadj\n",
    "                if p_adjust == 'bonferroni':\n",
    "                    p_adj = min(1.0, p_unadj * n_comparisons)\n",
    "                \n",
    "                p_matrix_unadj.loc[g1, g2] = p_unadj\n",
    "                p_matrix_unadj.loc[g2, g1] = p_unadj\n",
    "                p_matrix_adj.loc[g1, g2] = p_adj\n",
    "                p_matrix_adj.loc[g2, g1] = p_adj\n",
    "    \n",
    "    return p_matrix_adj, p_matrix_unadj\n",
    "\n",
    "def simple_logistic_regression(X, y, max_iter=100):\n",
    "    \"\"\"\n",
    "    簡易ロジスティック回帰（勾配降下法）\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    beta = np.zeros(p)\n",
    "    \n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        z = X @ beta\n",
    "        prob = sigmoid(z)\n",
    "        \n",
    "        gradient = X.T @ (y - prob)\n",
    "        W = np.diag(prob * (1 - prob) + 1e-10)\n",
    "        H = -X.T @ W @ X\n",
    "        \n",
    "        try:\n",
    "            delta = np.linalg.solve(H, gradient)\n",
    "            beta_new = beta - delta\n",
    "            \n",
    "            if np.max(np.abs(delta)) < 1e-6:\n",
    "                break\n",
    "            beta = beta_new\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    z = X @ beta\n",
    "    prob = sigmoid(z)\n",
    "    W = np.diag(prob * (1 - prob) + 1e-10)\n",
    "    try:\n",
    "        cov = np.linalg.inv(X.T @ W @ X)\n",
    "        se = np.sqrt(np.diag(cov))\n",
    "    except:\n",
    "        se = np.ones(len(beta)) * np.nan\n",
    "    \n",
    "    z_stats = beta / (se + 1e-10)\n",
    "    p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "    \n",
    "    odds_ratios = np.exp(beta)\n",
    "    ci_lower = np.exp(beta - 1.96 * se)\n",
    "    ci_upper = np.exp(beta + 1.96 * se)\n",
    "    \n",
    "    return {\n",
    "        'coefficients': beta,\n",
    "        'se': se,\n",
    "        'p_values': p_values,\n",
    "        'odds_ratios': odds_ratios,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2818f",
   "metadata": {},
   "source": [
    "#### データの読み込みとデータ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(filepath):\n",
    "    \"\"\"\n",
    "    データの読み込みと前処理\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    abuse_order = [\"Physical Abuse\", \"Neglect\", \"Emotional Abuse\", \"Sexual Abuse\"]\n",
    "    df['abuse'] = pd.Categorical(df['abuse'], categories=abuse_order, ordered=True)\n",
    "    \n",
    "    if 'occlusalRelationship' in df.columns:\n",
    "        occlusal_order = [\"Normal Occlusion\", \"Crowding\", \"Anterior Crossbite\", \"Open Bite\", \n",
    "                          \"Maxillary Protrusion\", \"Crossbite\", \"Others\"]\n",
    "        df['occlusalRelationship'] = pd.Categorical(df['occlusalRelationship'], \n",
    "                                                     categories=occlusal_order, ordered=True)\n",
    "    if 'needTOBEtreated' in df.columns:\n",
    "        df['needTOBEtreated'] = pd.Categorical(df['needTOBEtreated'], \n",
    "                                                categories=[\"No Treatment Required\", \"Treatment Required\"], \n",
    "                                                ordered=True)\n",
    "    if 'gingivitis' in df.columns:\n",
    "        df['gingivitis'] = pd.Categorical(df['gingivitis'], \n",
    "                                          categories=[\"No Gingivitis\", \"Gingivitis\"], \n",
    "                                          ordered=True)\n",
    "    if 'OralCleanStatus' in df.columns:\n",
    "        df['OralCleanStatus'] = pd.Categorical(df['OralCleanStatus'], \n",
    "                                                categories=[\"Poor\", \"Fair\", \"Good\"], \n",
    "                                                ordered=True)\n",
    "    if 'habits' in df.columns:\n",
    "        habits_order = [\"None\", \"Digit Sucking\", \"Nail biting\", \"Tongue Thrusting\", \"Smoking\", \"Others\"]\n",
    "        df['habits'] = pd.Categorical(df['habits'], categories=habits_order, ordered=True)\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['age_year'], \n",
    "                             bins=[0, 6, 12, 18],\n",
    "                             labels=['Early Childhood (2-6)', \n",
    "                                    'Middle Childhood (7-12)', \n",
    "                                    'Adolescence (13-18)'],\n",
    "                             right=True)\n",
    "    \n",
    "    if 'DMFT_Index' in df.columns:\n",
    "        df['has_caries'] = (df['DMFT_Index'] > 0).astype(int)\n",
    "    \n",
    "    if 'Perm_D' in df.columns and 'Baby_d' in df.columns:\n",
    "        df['has_untreated_caries'] = ((df['Perm_D'] + df['Baby_d']) > 0).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf61657",
   "metadata": {},
   "source": [
    "#### Table 1: 対象者の基本特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table1_demographics(df):\n",
    "    \"\"\"\n",
    "    Table 1: 虐待分類別の人口統計学的特性\n",
    "    \"\"\"\n",
    "    abuse_types = df['abuse'].cat.categories\n",
    "    results = []\n",
    "    \n",
    "    # 総数\n",
    "    total_row = {'Variable': 'Total N', 'Category': ''}\n",
    "    for abuse in abuse_types:\n",
    "        n = df[df['abuse'] == abuse].shape[0]\n",
    "        total_row[abuse] = str(n)\n",
    "    total_row['Total'] = str(df.shape[0])\n",
    "    total_row['p-value'] = ''\n",
    "    results.append(total_row)\n",
    "    \n",
    "    # 性別分布\n",
    "    sex_row_header = {'Variable': 'Sex', 'Category': '', **{abuse: '' for abuse in abuse_types}, \n",
    "                      'Total': '', 'p-value': ''}\n",
    "    results.append(sex_row_header)\n",
    "    \n",
    "    contingency_sex = pd.crosstab(df['abuse'], df['sex'])\n",
    "    chi2_sex, p_sex, _, _ = chi2_contingency(contingency_sex)\n",
    "    \n",
    "    for sex in ['Male', 'Female']:\n",
    "        row = {'Variable': '', 'Category': f'  {sex}'}\n",
    "        for abuse in abuse_types:\n",
    "            n = df[(df['abuse'] == abuse) & (df['sex'] == sex)].shape[0]\n",
    "            total_abuse = df[df['abuse'] == abuse].shape[0]\n",
    "            pct = (n / total_abuse * 100) if total_abuse > 0 else 0\n",
    "            row[abuse] = f\"{n} ({pct:.1f}%)\"\n",
    "        \n",
    "        total_n = df[df['sex'] == sex].shape[0]\n",
    "        total_pct = total_n / df.shape[0] * 100\n",
    "        row['Total'] = f\"{total_n} ({total_pct:.1f}%)\"\n",
    "        row['p-value'] = f\"{p_sex:.3f}\" if sex == 'Male' else ''\n",
    "        results.append(row)\n",
    "    \n",
    "    # 年齢（連続変数）\n",
    "    age_row = {'Variable': 'Age (years)', 'Category': 'Mean ± SD'}\n",
    "    for abuse in abuse_types:\n",
    "        subset = df[df['abuse'] == abuse]['age_year']\n",
    "        age_row[abuse] = f\"{subset.mean():.1f} ± {subset.std():.1f}\"\n",
    "    total_age = df['age_year']\n",
    "    age_row['Total'] = f\"{total_age.mean():.1f} ± {total_age.std():.1f}\"\n",
    "    \n",
    "    groups = [df[df['abuse'] == abuse]['age_year'].dropna() for abuse in abuse_types]\n",
    "    _, p_age = kruskal(*groups)\n",
    "    age_row['p-value'] = f\"{p_age:.3f}\"\n",
    "    results.append(age_row)\n",
    "    \n",
    "    # 年齢（中央値・四分位範囲）\n",
    "    age_median_row = {'Variable': '', 'Category': 'Median [IQR]'}\n",
    "    for abuse in abuse_types:\n",
    "        subset = df[df['abuse'] == abuse]['age_year']\n",
    "        q25, q50, q75 = subset.quantile([0.25, 0.5, 0.75])\n",
    "        age_median_row[abuse] = f\"{q50:.0f} [{q25:.0f}-{q75:.0f}]\"\n",
    "    q25, q50, q75 = df['age_year'].quantile([0.25, 0.5, 0.75])\n",
    "    age_median_row['Total'] = f\"{q50:.0f} [{q25:.0f}-{q75:.0f}]\"\n",
    "    age_median_row['p-value'] = ''\n",
    "    results.append(age_median_row)\n",
    "    \n",
    "    # 年齢グループ\n",
    "    if 'age_group' in df.columns:\n",
    "        age_group_header = {'Variable': 'Age Group', 'Category': '', **{abuse: '' for abuse in abuse_types},\n",
    "                            'Total': '', 'p-value': ''}\n",
    "        results.append(age_group_header)\n",
    "        \n",
    "        df_valid = df.dropna(subset=['age_group'])\n",
    "        contingency_age = pd.crosstab(df_valid['abuse'], df_valid['age_group'])\n",
    "        chi2_age_grp, p_age_grp, _, _ = chi2_contingency(contingency_age)\n",
    "        \n",
    "        first_group = True\n",
    "        for age_grp in df['age_group'].cat.categories:\n",
    "            row = {'Variable': '', 'Category': f'  {age_grp}'}\n",
    "            for abuse in abuse_types:\n",
    "                n = df[(df['abuse'] == abuse) & (df['age_group'] == age_grp)].shape[0]\n",
    "                total_abuse = df[df['abuse'] == abuse].shape[0]\n",
    "                pct = (n / total_abuse * 100) if total_abuse > 0 else 0\n",
    "                row[abuse] = f\"{n} ({pct:.1f}%)\"\n",
    "            \n",
    "            total_n = df[df['age_group'] == age_grp].shape[0]\n",
    "            total_pct = total_n / df.shape[0] * 100\n",
    "            row['Total'] = f\"{total_n} ({total_pct:.1f}%)\"\n",
    "            row['p-value'] = f\"{p_age_grp:.3f}\" if first_group else ''\n",
    "            first_group = False\n",
    "            results.append(row)\n",
    "    \n",
    "    table1 = pd.DataFrame(results)\n",
    "    return table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b337487",
   "metadata": {},
   "source": [
    "#### Table 2: 口腔内状況の記述統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26633685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table2_oral_health_descriptive(df):\n",
    "    \"\"\"\n",
    "    Table 2: 虐待分類別の口腔内状況（記述統計）\n",
    "    \"\"\"\n",
    "    abuse_types = df['abuse'].cat.categories\n",
    "    \n",
    "    continuous_vars = [\n",
    "        ('DMFT_Index', 'DMFT Index (Total)'),\n",
    "        ('Perm_DMFT', 'Permanent DMFT'),\n",
    "        ('Baby_DMFT', 'Primary dmft'),\n",
    "        ('Perm_D', 'Permanent D (Decayed)'),\n",
    "        ('Perm_M', 'Permanent M (Missing)'),\n",
    "        ('Perm_F', 'Permanent F (Filled)'),\n",
    "        ('Baby_d', 'Primary d (decayed)'),\n",
    "        ('Baby_m', 'Primary m (missing)'),\n",
    "        ('Baby_f', 'Primary f (filled)'),\n",
    "        ('C0_Count', 'C0 (Incipient Caries)'),\n",
    "        ('Healthy_Rate', 'Healthy Teeth Rate (%)'),\n",
    "        ('Care_Index', 'Care Index (%)'),\n",
    "        ('UTN_Score', 'Untreated Caries Rate (%)'),\n",
    "        ('Trauma_Count', 'Dental Trauma Count'),\n",
    "        ('RDT_Count', 'Retained Deciduous Teeth')\n",
    "    ]\n",
    "    \n",
    "    results_continuous = []\n",
    "    \n",
    "    for var_name, var_label in continuous_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        row = {'Variable': var_label}\n",
    "        \n",
    "        for abuse in abuse_types:\n",
    "            subset = df[df['abuse'] == abuse][var_name].dropna()\n",
    "            if len(subset) > 0:\n",
    "                mean = subset.mean()\n",
    "                std = subset.std()\n",
    "                median = subset.median()\n",
    "                q25, q75 = subset.quantile([0.25, 0.75])\n",
    "                row[f'{abuse}_Mean_SD'] = f\"{mean:.2f} ± {std:.2f}\"\n",
    "                row[f'{abuse}_Median_IQR'] = f\"{median:.1f} [{q25:.1f}-{q75:.1f}]\"\n",
    "            else:\n",
    "                row[f'{abuse}_Mean_SD'] = 'N/A'\n",
    "                row[f'{abuse}_Median_IQR'] = 'N/A'\n",
    "        \n",
    "        total = df[var_name].dropna()\n",
    "        if len(total) > 0:\n",
    "            row['Total_Mean_SD'] = f\"{total.mean():.2f} ± {total.std():.2f}\"\n",
    "            row['Total_Median_IQR'] = f\"{total.median():.1f} [{total.quantile(0.25):.1f}-{total.quantile(0.75):.1f}]\"\n",
    "        \n",
    "        groups = [df[df['abuse'] == abuse][var_name].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                _, p_val = kruskal(*groups)\n",
    "                row['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "            except:\n",
    "                row['p-value'] = 'N/A'\n",
    "        else:\n",
    "            row['p-value'] = 'N/A'\n",
    "        \n",
    "        results_continuous.append(row)\n",
    "    \n",
    "    categorical_vars = [\n",
    "        ('gingivitis', 'Gingivitis'),\n",
    "        ('needTOBEtreated', 'Treatment Need'),\n",
    "        ('occlusalRelationship', 'Occlusal Relationship'),\n",
    "        ('OralCleanStatus', 'Oral Hygiene Status'),\n",
    "        ('habits', 'Oral Habits')\n",
    "    ]\n",
    "    \n",
    "    results_categorical = []\n",
    "    \n",
    "    for var_name, var_label in categorical_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        header_row = {'Variable': var_label, 'Category': ''}\n",
    "        for abuse in abuse_types:\n",
    "            header_row[f'{abuse}_n'] = ''\n",
    "            header_row[f'{abuse}_%'] = ''\n",
    "        header_row['Total_n'] = ''\n",
    "        header_row['Total_%'] = ''\n",
    "        header_row['p-value'] = ''\n",
    "        results_categorical.append(header_row)\n",
    "        \n",
    "        df_valid = df.dropna(subset=[var_name])\n",
    "        contingency = pd.crosstab(df_valid['abuse'], df_valid[var_name])\n",
    "        try:\n",
    "            chi2, p_val, _, _ = chi2_contingency(contingency)\n",
    "        except:\n",
    "            p_val = np.nan\n",
    "        \n",
    "        categories = df[var_name].cat.categories if hasattr(df[var_name], 'cat') else df[var_name].dropna().unique()\n",
    "        first_cat = True\n",
    "        \n",
    "        for cat in categories:\n",
    "            row = {'Variable': '', 'Category': f'  {cat}'}\n",
    "            \n",
    "            for abuse in abuse_types:\n",
    "                n = df[(df['abuse'] == abuse) & (df[var_name] == cat)].shape[0]\n",
    "                total_abuse = df[(df['abuse'] == abuse) & (df[var_name].notna())].shape[0]\n",
    "                pct = (n / total_abuse * 100) if total_abuse > 0 else 0\n",
    "                row[f'{abuse}_n'] = n\n",
    "                row[f'{abuse}_%'] = f\"{pct:.1f}\"\n",
    "            \n",
    "            total_n = df[df[var_name] == cat].shape[0]\n",
    "            total_valid = df[df[var_name].notna()].shape[0]\n",
    "            total_pct = (total_n / total_valid * 100) if total_valid > 0 else 0\n",
    "            row['Total_n'] = total_n\n",
    "            row['Total_%'] = f\"{total_pct:.1f}\"\n",
    "            \n",
    "            if first_cat and not np.isnan(p_val):\n",
    "                row['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "            else:\n",
    "                row['p-value'] = ''\n",
    "            first_cat = False\n",
    "            \n",
    "            results_categorical.append(row)\n",
    "    \n",
    "    table2_continuous = pd.DataFrame(results_continuous)\n",
    "    table2_categorical = pd.DataFrame(results_categorical)\n",
    "    \n",
    "    return table2_continuous, table2_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c24ed",
   "metadata": {},
   "source": [
    "#### Table 3: 統計解析結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table3_statistical_comparisons(df):\n",
    "    \"\"\"\n",
    "    Table 3: 虐待分類間の統計的比較\n",
    "    \"\"\"\n",
    "    abuse_types = list(df['abuse'].cat.categories)\n",
    "    \n",
    "    continuous_vars = [\n",
    "        'DMFT_Index', 'Perm_DMFT', 'Baby_DMFT', \n",
    "        'Perm_D', 'Perm_M', 'Perm_F',\n",
    "        'Baby_d', 'Baby_m', 'Baby_f',\n",
    "        'C0_Count', 'Healthy_Rate', 'Care_Index', \n",
    "        'UTN_Score', 'Trauma_Count',\"DMFT_C0\",\"Perm_DMFT_C0\",\"Baby_DMFT_C0\"\n",
    "    ]\n",
    "    \n",
    "    overall_results = []\n",
    "    \n",
    "    for var in continuous_vars:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        groups = [df[df['abuse'] == abuse][var].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        \n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            h_stat, p_kw = kruskal(*groups)\n",
    "            overall_results.append({\n",
    "                'Variable': var,\n",
    "                'Test': 'Kruskal-Wallis',\n",
    "                'Statistic': f\"{h_stat:.3f}\",\n",
    "                'p-value': f\"{p_kw:.4f}\" if p_kw >= 0.0001 else \"<0.0001\",\n",
    "                'Significant': 'Yes' if p_kw < 0.05 else 'No'\n",
    "            })\n",
    "        except Exception as e:\n",
    "            overall_results.append({\n",
    "                'Variable': var,\n",
    "                'Test': 'Kruskal-Wallis',\n",
    "                'Statistic': 'N/A',\n",
    "                'p-value': 'N/A',\n",
    "                'Significant': 'N/A'\n",
    "            })\n",
    "    \n",
    "    posthoc_results = []\n",
    "    tidy_posthoc_pairwise = []\n",
    "    \n",
    "    for var in continuous_vars:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Only run Dunn's test if Kruskal-Wallis was significant\n",
    "        kw_p = next((r['p-value'] for r in overall_results if r['Variable'] == var and r['Significant'] == 'Yes'), None)\n",
    "        if kw_p is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dunn_adj, dunn_unadj = posthoc_dunn(df, val_col=var, group_col='abuse', p_adjust='bonferroni')\n",
    "            \n",
    "            for i, abuse1 in enumerate(abuse_types):\n",
    "                for abuse2 in abuse_types[i+1:]:\n",
    "                    if abuse1 in dunn_adj.index and abuse2 in dunn_adj.columns:\n",
    "                        p_adj = dunn_adj.loc[abuse1, abuse2]\n",
    "                        p_unadj = dunn_unadj.loc[abuse1, abuse2]\n",
    "                        \n",
    "                        posthoc_results.append({\n",
    "                            'Variable': var,\n",
    "                            'Comparison': f\"{abuse1} vs {abuse2}\",\n",
    "                            'p-value (adjusted)': f\"{p_adj:.4f}\" if p_adj >= 0.0001 else \"<0.0001\",\n",
    "                            'Significant': 'Yes' if p_adj < 0.05 else 'No'\n",
    "                        })\n",
    "                        \n",
    "                        # Added tidy summary table for pairwise significance\n",
    "                        tidy_posthoc_pairwise.append({\n",
    "                            'variable': var,\n",
    "                            'group1': abuse1,\n",
    "                            'group2': abuse2,\n",
    "                            'p_unadjusted': p_unadj,\n",
    "                            'p_adjusted': p_adj,\n",
    "                            'significant': p_adj < 0.05\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    pairwise_results = []\n",
    "    abuse_pairs = list(itertools.combinations(abuse_types, 2))\n",
    "    n_comparisons = len(abuse_pairs) * len(continuous_vars)\n",
    "    bonferroni_threshold = 0.05 / n_comparisons if n_comparisons > 0 else 0.05\n",
    "    \n",
    "    for var in continuous_vars:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        for abuse1, abuse2 in abuse_pairs:\n",
    "            group1 = df[df['abuse'] == abuse1][var].dropna()\n",
    "            group2 = df[df['abuse'] == abuse2][var].dropna()\n",
    "            \n",
    "            if len(group1) == 0 or len(group2) == 0:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                u_stat, p_val = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "                \n",
    "                n1, n2 = len(group1), len(group2)\n",
    "                r = 1 - (2 * u_stat) / (n1 * n2)\n",
    "                \n",
    "                pairwise_results.append({\n",
    "                    'Variable': var,\n",
    "                    'Group1': abuse1,\n",
    "                    'Group2': abuse2,\n",
    "                    'Group1_Median': f\"{group1.median():.2f}\",\n",
    "                    'Group2_Median': f\"{group2.median():.2f}\",\n",
    "                    'U_Statistic': f\"{u_stat:.0f}\",\n",
    "                    'p-value': f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\",\n",
    "                    'Effect_Size_r': f\"{r:.3f}\",\n",
    "                    'Significant_Bonferroni': 'Yes' if p_val < bonferroni_threshold else 'No'\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    table3_overall = pd.DataFrame(overall_results)\n",
    "    table3_posthoc = pd.DataFrame(posthoc_results)\n",
    "    table3_pairwise = pd.DataFrame(pairwise_results)\n",
    "    \n",
    "    # Standardize tidy post-hoc with analysis type\n",
    "    for r in tidy_posthoc_pairwise:\n",
    "        r['analysis_type'] = 'Table 3: Overall'\n",
    "    \n",
    "    return table3_overall, table3_posthoc, table3_pairwise, tidy_posthoc_pairwise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec7582",
   "metadata": {},
   "source": [
    "#### Table 4: 多変量解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table4_multivariate_analysis(df):\n",
    "    \"\"\"\n",
    "    Table 4: 年齢・性別調整済みロジスティック回帰分析\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    df_analysis = df.copy()\n",
    "    df_analysis['sex_male'] = (df_analysis['sex'] == 'Male').astype(int)\n",
    "    \n",
    "    reference_category = 'Physical Abuse'\n",
    "    comparison_categories = ['Neglect', 'Emotional Abuse', 'Sexual Abuse']\n",
    "    \n",
    "    outcomes = [\n",
    "        ('has_caries', 'Caries Experience (DMFT>0)'),\n",
    "        ('has_untreated_caries', 'Untreated Caries'),\n",
    "    ]\n",
    "    \n",
    "    if 'gingivitis' in df_analysis.columns:\n",
    "        df_analysis['gingivitis_binary'] = (df_analysis['gingivitis'] == 'Gingivitis').astype(int)\n",
    "        outcomes.append(('gingivitis_binary', 'Gingivitis'))\n",
    "    \n",
    "    if 'needTOBEtreated' in df_analysis.columns:\n",
    "        df_analysis['treatment_need'] = (df_analysis['needTOBEtreated'] == 'Treatment Required').astype(int)\n",
    "        outcomes.append(('treatment_need', 'Treatment Need'))\n",
    "    \n",
    "    for outcome_var, outcome_label in outcomes:\n",
    "        if outcome_var not in df_analysis.columns:\n",
    "            continue\n",
    "        \n",
    "        for comparison in comparison_categories:\n",
    "            df_model = df_analysis[df_analysis['abuse'].isin([reference_category, comparison])].copy()\n",
    "            df_model = df_model[[outcome_var, 'age_year', 'sex_male', 'abuse']].dropna()\n",
    "            \n",
    "            if len(df_model) < 50:\n",
    "                continue\n",
    "            \n",
    "            df_model['comparison'] = (df_model['abuse'] == comparison).astype(int)\n",
    "            \n",
    "            try:\n",
    "                X = np.column_stack([\n",
    "                    np.ones(len(df_model)),\n",
    "                    df_model['age_year'].values,\n",
    "                    df_model['sex_male'].values,\n",
    "                    df_model['comparison'].values\n",
    "                ])\n",
    "                y = df_model[outcome_var].values\n",
    "                \n",
    "                result = simple_logistic_regression(X, y)\n",
    "                \n",
    "                odds_ratio = result['odds_ratios'][3]\n",
    "                ci_lower = result['ci_lower'][3]\n",
    "                ci_upper = result['ci_upper'][3]\n",
    "                p_val = result['p_values'][3]\n",
    "                \n",
    "                results.append({\n",
    "                    'Outcome': outcome_label,\n",
    "                    'Comparison': f\"{comparison} vs {reference_category}\",\n",
    "                    'Odds Ratio': f\"{odds_ratio:.2f}\",\n",
    "                    '95% CI': f\"({ci_lower:.2f}-{ci_upper:.2f})\",\n",
    "                    'p-value': f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\",\n",
    "                    'Adjusted_for': 'Age, Sex'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    'Outcome': outcome_label,\n",
    "                    'Comparison': f\"{comparison} vs {reference_category}\",\n",
    "                    'Odds Ratio': 'N/A',\n",
    "                    '95% CI': 'N/A',\n",
    "                    'p-value': 'N/A',\n",
    "                    'Adjusted_for': 'Age, Sex'\n",
    "                })\n",
    "    \n",
    "    table4 = pd.DataFrame(results)\n",
    "    return table4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc47a54",
   "metadata": {},
   "source": [
    "#### Table : DMFT by Life Stage and Abuse Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a08eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table5_dmft_by_lifestage_abuse(df):\n",
    "    \"\"\"\n",
    "    Table 5: DMFT_Index analysis by life_stage and abuse type\n",
    "    \n",
    "    Returns a DataFrame with descriptive statistics for each life_stage × abuse combination\n",
    "    \"\"\"\n",
    "    abuse_types = list(df['abuse'].cat.categories)\n",
    "    life_stages = df['age_group'].dropna().unique()\n",
    "    \n",
    "    # Sort life_stages if they have a natural order\n",
    "    life_stage_order = ['Early Childhood (2-6)', \n",
    "                                    'Middle Childhood (7-12)', \n",
    "                                    'Adolescence (13-18)']\n",
    "    life_stages = [ls for ls in life_stage_order if ls in life_stages] + \\\n",
    "                  [ls for ls in life_stages if ls not in life_stage_order]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for life_stage in life_stages:\n",
    "        df_stage = df[df['age_group'] == life_stage]\n",
    "        \n",
    "        # Kruskal-Wallis test across abuse types within this life_stage\n",
    "        groups = [df_stage[df_stage['abuse'] == abuse]['DMFT_Index'].dropna() \n",
    "                  for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        \n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                h_stat, p_kw = kruskal(*groups)\n",
    "                p_val_str = f\"{p_kw:.4f}\" if p_kw >= 0.0001 else \"<0.0001\"\n",
    "            except:\n",
    "                p_val_str = \"N/A\"\n",
    "        else:\n",
    "            p_val_str = \"N/A\"\n",
    "        \n",
    "        first_row = True\n",
    "        for abuse in abuse_types:\n",
    "            subset = df_stage[(df_stage['abuse'] == abuse)]['DMFT_Index'].dropna()\n",
    "            \n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            row = {\n",
    "                'Life_Stage': life_stage if first_row else '',\n",
    "                'Abuse_Type': abuse,\n",
    "                'N': len(subset),\n",
    "                'Mean': f\"{subset.mean():.2f}\",\n",
    "                'SD': f\"{subset.std():.2f}\",\n",
    "                'Median': f\"{subset.median():.1f}\",\n",
    "                '25%': f\"{subset.quantile(0.25):.1f}\",\n",
    "                '75%': f\"{subset.quantile(0.75):.1f}\",\n",
    "                'Min': f\"{subset.min():.0f}\",\n",
    "                'Max': f\"{subset.max():.0f}\",\n",
    "                'p-value (KW)': p_val_str if first_row else ''\n",
    "            }\n",
    "            results.append(row)\n",
    "            first_row = False\n",
    "    \n",
    "    # Add overall summary by life stage (all abuse types combined)\n",
    "    results.append({\n",
    "        'Life_Stage': '=== OVERALL BY LIFE STAGE ===',\n",
    "        'Abuse_Type': '(Combined)',\n",
    "        'N': '---',\n",
    "        'Mean': '---',\n",
    "        'SD': '---',\n",
    "        'Median': '---',\n",
    "        '25%': '---',\n",
    "        '75%': '---',\n",
    "        'Min': '---',\n",
    "        'Max': '---',\n",
    "        'p-value (KW)': '---'\n",
    "    })\n",
    "    \n",
    "    # Kruskal-Wallis test across life stages (all abuse types combined)\n",
    "    life_stage_groups = [df[df['age_group'] == ls]['DMFT_Index'].dropna() \n",
    "                         for ls in life_stages]\n",
    "    life_stage_groups = [g for g in life_stage_groups if len(g) > 0]\n",
    "    \n",
    "    if len(life_stage_groups) >= 2:\n",
    "        try:\n",
    "            h_stat, p_kw_lifestage = kruskal(*life_stage_groups)\n",
    "            p_val_lifestage_str = f\"{p_kw_lifestage:.4f}\" if p_kw_lifestage >= 0.0001 else \"<0.0001\"\n",
    "        except:\n",
    "            p_val_lifestage_str = \"N/A\"\n",
    "    else:\n",
    "        p_val_lifestage_str = \"N/A\"\n",
    "    \n",
    "    first_lifestage = True\n",
    "    for life_stage in life_stages:\n",
    "        subset = df[df['age_group'] == life_stage]['DMFT_Index'].dropna()\n",
    "        if len(subset) > 0:\n",
    "            results.append({\n",
    "                'Life_Stage': life_stage,\n",
    "                'Abuse_Type': 'All abuse types',\n",
    "                'N': len(subset),\n",
    "                'Mean': f\"{subset.mean():.2f}\",\n",
    "                'SD': f\"{subset.std():.2f}\",\n",
    "                'Median': f\"{subset.median():.1f}\",\n",
    "                '25%': f\"{subset.quantile(0.25):.1f}\",\n",
    "                '75%': f\"{subset.quantile(0.75):.1f}\",\n",
    "                'Min': f\"{subset.min():.0f}\",\n",
    "                'Max': f\"{subset.max():.0f}\",\n",
    "                'p-value (KW)': p_val_lifestage_str if first_lifestage else ''\n",
    "            })\n",
    "            first_lifestage = False\n",
    "    \n",
    "    tidy_posthoc = []\n",
    "    # Add post-hoc for life stage strata\n",
    "    for life_stage in life_stages:\n",
    "        df_stage = df[df['age_group'] == life_stage]\n",
    "        groups = [df_stage[df_stage['abuse'] == abuse]['DMFT_Index'].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                _, p_kw = kruskal(*groups)\n",
    "                if p_kw < 0.05:\n",
    "                    dunn_adj, dunn_unadj = posthoc_dunn(df_stage, val_col='DMFT_Index', group_col='abuse', p_adjust='bonferroni')\n",
    "                    for i, abuse1 in enumerate(abuse_types):\n",
    "                        for abuse2 in abuse_types[i+1:]:\n",
    "                            if abuse1 in dunn_adj.index and abuse2 in dunn_adj.columns:\n",
    "                                tidy_posthoc.append({\n",
    "                                    'analysis_type': f'Table 5: {life_stage}',\n",
    "                                    'variable': 'DMFT_Index',\n",
    "                                    'group1': abuse1,\n",
    "                                    'group2': abuse2,\n",
    "                                    'p_unadjusted': dunn_unadj.loc[abuse1, abuse2],\n",
    "                                    'p_adjusted': dunn_adj.loc[abuse1, abuse2],\n",
    "                                    'significant': dunn_adj.loc[abuse1, abuse2] < 0.05\n",
    "                                })\n",
    "            except: pass\n",
    "\n",
    "    # Add post-hoc for overall life stage comparison\n",
    "    if len(life_stage_groups) >= 2 and p_kw_lifestage < 0.05:\n",
    "        try:\n",
    "            dunn_adj, dunn_unadj = posthoc_dunn(df.dropna(subset=['age_group']), val_col='DMFT_Index', group_col='age_group', p_adjust='bonferroni')\n",
    "            for i, ls1 in enumerate(life_stages):\n",
    "                for ls2 in life_stages[i+1:]:\n",
    "                    if ls1 in dunn_adj.index and ls2 in dunn_adj.columns:\n",
    "                        tidy_posthoc.append({\n",
    "                            'analysis_type': 'Table 5: Life Stage Overall',\n",
    "                            'variable': 'DMFT_Index',\n",
    "                            'group1': ls1,\n",
    "                            'group2': ls2,\n",
    "                            'p_unadjusted': dunn_unadj.loc[ls1, ls2],\n",
    "                            'p_adjusted': dunn_adj.loc[ls1, ls2],\n",
    "                            'significant': dunn_adj.loc[ls1, ls2] < 0.05\n",
    "                        })\n",
    "        except: pass\n",
    "\n",
    "    # Add pairwise significance section to the table itself\n",
    "    results.append({\n",
    "        'Life_Stage': '=== POST-HOC pairwise (Dunn\\'s) ===',\n",
    "        'Abuse_Type': '(Only if KW p < 0.05)',\n",
    "        'N': '', 'Mean': '', 'SD': '', 'Median': '', '25%': '', '75%': '', 'Min': '', 'Max': '', 'p-value (KW)': ''\n",
    "    })\n",
    "    \n",
    "    for tp in tidy_posthoc:\n",
    "        results.append({\n",
    "            'Life_Stage': f\"Post-hoc: {tp['analysis_type']}\",\n",
    "            'Abuse_Type': f\"{tp['group1']} vs {tp['group2']}\",\n",
    "            'N': 'Significant' if tp['significant'] else 'n.s.',\n",
    "            'Mean': f\"p_adj={tp['p_adjusted']:.4f}\",\n",
    "            'SD': f\"p_unadj={tp['p_unadjusted']:.4f}\",\n",
    "            'Median': '', '25%': '', '75%': '', 'Min': '', 'Max': '', 'p-value (KW)': ''\n",
    "        })\n",
    "\n",
    "    table5 = pd.DataFrame(results)\n",
    "    return table5, tidy_posthoc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354b0ba",
   "metadata": {},
   "source": [
    "#### Table : Caries Prevalence and Treatment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table5_5_caries_prevalence_treatment(df):\n",
    "    \"\"\"\n",
    "    Table 5.5: Caries Prevalence and Treatment Status Analysis\n",
    "    \n",
    "    Calculates:\n",
    "    1. Percentage of children with caries (DMFT_Index > 0) - total and by abuse type\n",
    "    2. Percentage of children where f+F = DMFT_Index (fully treated caries)\n",
    "    3. Percentage of children where f+F = 0 (no filled teeth)\n",
    "    \n",
    "    Also includes descriptive statistics for C0 variables:\n",
    "    - DMFT_C0 (total DMFT including C0)\n",
    "    - Perm_DMFT_C0 (permanent teeth DMFT including C0)\n",
    "    - Baby_DMFT_C0 (baby teeth dmft including C0)\n",
    "    \n",
    "    Returns a DataFrame with these statistics broken down by abuse type\n",
    "    \"\"\"\n",
    "    abuse_types = list(df['abuse'].cat.categories)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # ========== SECTION 1: Caries Prevalence ==========\n",
    "    results.append({\n",
    "        'Variable': '=== CARIES PREVALENCE ===',\n",
    "        'Category': '',\n",
    "        **{abuse: '' for abuse in abuse_types},\n",
    "        'Total': '',\n",
    "        'p-value': ''\n",
    "    })\n",
    "    \n",
    "    # 1. Percentage of children with caries (DMFT_Index > 0)\n",
    "    row_caries = {'Variable': 'Children with Caries', 'Category': 'DMFT_Index > 0'}\n",
    "    \n",
    "    for abuse in abuse_types:\n",
    "        subset = df[df['abuse'] == abuse]\n",
    "        n_total = len(subset)\n",
    "        n_caries = (subset['DMFT_Index'] > 0).sum()\n",
    "        pct = (n_caries / n_total * 100) if n_total > 0 else 0\n",
    "        row_caries[abuse] = f\"{n_caries}/{n_total} ({pct:.1f}%)\"\n",
    "    \n",
    "    # Total\n",
    "    n_total_all = len(df)\n",
    "    n_caries_all = (df['DMFT_Index'] > 0).sum()\n",
    "    pct_all = (n_caries_all / n_total_all * 100) if n_total_all > 0 else 0\n",
    "    row_caries['Total'] = f\"{n_caries_all}/{n_total_all} ({pct_all:.1f}%)\"\n",
    "    \n",
    "    # Chi-square test for caries prevalence\n",
    "    df['has_caries'] = (df['DMFT_Index'] > 0).astype(int)\n",
    "    contingency = pd.crosstab(df['abuse'], df['has_caries'])\n",
    "    try:\n",
    "        chi2, p_val, _, _ = chi2_contingency(contingency)\n",
    "        row_caries['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "    except:\n",
    "        row_caries['p-value'] = 'N/A'\n",
    "    results.append(row_caries)\n",
    "    \n",
    "    # ========== SECTION 2: Treatment Status ==========\n",
    "    results.append({\n",
    "        'Variable': '=== TREATMENT STATUS ===',\n",
    "        'Category': '',\n",
    "        **{abuse: '' for abuse in abuse_types},\n",
    "        'Total': '',\n",
    "        'p-value': ''\n",
    "    })\n",
    "    \n",
    "    # Calculate f+F for the dataset\n",
    "    df['filled_total'] = df['Perm_F'] + df['Baby_f']\n",
    "    \n",
    "    # 2. Percentage of children where f+F = DMFT_Index (fully treated)\n",
    "    row_fully_treated = {'Variable': 'Fully Treated Caries', 'Category': 'f+F = DMFT_Index'}\n",
    "    \n",
    "    # Only consider children with caries (DMFT_Index > 0)\n",
    "    df_with_caries = df[df['DMFT_Index'] > 0]\n",
    "    \n",
    "    for abuse in abuse_types:\n",
    "        subset = df_with_caries[df_with_caries['abuse'] == abuse]\n",
    "        n_total = len(subset)\n",
    "        n_fully_treated = (subset['filled_total'] == subset['DMFT_Index']).sum()\n",
    "        pct = (n_fully_treated / n_total * 100) if n_total > 0 else 0\n",
    "        row_fully_treated[abuse] = f\"{n_fully_treated}/{n_total} ({pct:.1f}%)\"\n",
    "    \n",
    "    n_total_caries = len(df_with_caries)\n",
    "    n_fully_treated_all = (df_with_caries['filled_total'] == df_with_caries['DMFT_Index']).sum()\n",
    "    pct_fully_treated = (n_fully_treated_all / n_total_caries * 100) if n_total_caries > 0 else 0\n",
    "    row_fully_treated['Total'] = f\"{n_fully_treated_all}/{n_total_caries} ({pct_fully_treated:.1f}%)\"\n",
    "    \n",
    "    # Chi-square test for fully treated\n",
    "    df_with_caries = df_with_caries.copy()\n",
    "    df_with_caries['is_fully_treated'] = (df_with_caries['filled_total'] == df_with_caries['DMFT_Index']).astype(int)\n",
    "    contingency_treated = pd.crosstab(df_with_caries['abuse'], df_with_caries['is_fully_treated'])\n",
    "    try:\n",
    "        chi2, p_val, _, _ = chi2_contingency(contingency_treated)\n",
    "        row_fully_treated['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "    except:\n",
    "        row_fully_treated['p-value'] = 'N/A'\n",
    "    results.append(row_fully_treated)\n",
    "    \n",
    "    # 3. Percentage of children where f+F = 0 (no filled teeth)\n",
    "    row_no_filled = {'Variable': 'No Filled Teeth', 'Category': 'f+F = 0'}\n",
    "    \n",
    "    for abuse in abuse_types:\n",
    "        subset = df[df['abuse'] == abuse]\n",
    "        n_total = len(subset)\n",
    "        n_no_filled = (subset['filled_total'] == 0).sum()\n",
    "        pct = (n_no_filled / n_total * 100) if n_total > 0 else 0\n",
    "        row_no_filled[abuse] = f\"{n_no_filled}/{n_total} ({pct:.1f}%)\"\n",
    "    \n",
    "    n_total_all = len(df)\n",
    "    n_no_filled_all = (df['filled_total'] == 0).sum()\n",
    "    pct_no_filled = (n_no_filled_all / n_total_all * 100) if n_total_all > 0 else 0\n",
    "    row_no_filled['Total'] = f\"{n_no_filled_all}/{n_total_all} ({pct_no_filled:.1f}%)\"\n",
    "    \n",
    "    # Chi-square test for no filled teeth\n",
    "    df['has_no_filled'] = (df['filled_total'] == 0).astype(int)\n",
    "    contingency_nofilled = pd.crosstab(df['abuse'], df['has_no_filled'])\n",
    "    try:\n",
    "        chi2, p_val, _, _ = chi2_contingency(contingency_nofilled)\n",
    "        row_no_filled['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "    except:\n",
    "        row_no_filled['p-value'] = 'N/A'\n",
    "    results.append(row_no_filled)\n",
    "    \n",
    "    # ========== SECTION 3: C0 Variables Analysis ==========\n",
    "    results.append({\n",
    "        'Variable': '=== DMFT WITH C0 (INCIPIENT CARIES) ===',\n",
    "        'Category': '',\n",
    "        **{abuse: '' for abuse in abuse_types},\n",
    "        'Total': '',\n",
    "        'p-value': ''\n",
    "    })\n",
    "    \n",
    "    # C0 variables to analyze\n",
    "    c0_vars = [\n",
    "        ('DMFT_C0', 'Total DMFT + C0'),\n",
    "        ('Perm_DMFT_C0', 'Permanent DMFT + C0'),\n",
    "        ('Baby_DMFT_C0', 'Primary dmft + C0')\n",
    "    ]\n",
    "    \n",
    "    for var_name, var_label in c0_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Header row\n",
    "        row_header = {'Variable': var_label, 'Category': 'Mean ± SD'}\n",
    "        for abuse in abuse_types:\n",
    "            subset = df[df['abuse'] == abuse][var_name].dropna()\n",
    "            if len(subset) > 0:\n",
    "                row_header[abuse] = f\"{subset.mean():.2f} ± {subset.std():.2f}\"\n",
    "            else:\n",
    "                row_header[abuse] = 'N/A'\n",
    "        \n",
    "        total = df[var_name].dropna()\n",
    "        if len(total) > 0:\n",
    "            row_header['Total'] = f\"{total.mean():.2f} ± {total.std():.2f}\"\n",
    "        else:\n",
    "            row_header['Total'] = 'N/A'\n",
    "        \n",
    "        # Kruskal-Wallis test\n",
    "        groups = [df[df['abuse'] == abuse][var_name].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                _, p_val = kruskal(*groups)\n",
    "                row_header['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "            except:\n",
    "                row_header['p-value'] = 'N/A'\n",
    "        else:\n",
    "            row_header['p-value'] = 'N/A'\n",
    "        results.append(row_header)\n",
    "        \n",
    "        # Median row\n",
    "        row_median = {'Variable': '', 'Category': 'Median [IQR]'}\n",
    "        for abuse in abuse_types:\n",
    "            subset = df[df['abuse'] == abuse][var_name].dropna()\n",
    "            if len(subset) > 0:\n",
    "                q25, q50, q75 = subset.quantile([0.25, 0.5, 0.75])\n",
    "                row_median[abuse] = f\"{q50:.1f} [{q25:.1f}-{q75:.1f}]\"\n",
    "            else:\n",
    "                row_median[abuse] = 'N/A'\n",
    "        \n",
    "        if len(total) > 0:\n",
    "            q25, q50, q75 = total.quantile([0.25, 0.5, 0.75])\n",
    "            row_median['Total'] = f\"{q50:.1f} [{q25:.1f}-{q75:.1f}]\"\n",
    "        else:\n",
    "            row_median['Total'] = 'N/A'\n",
    "        row_median['p-value'] = ''\n",
    "        results.append(row_median)\n",
    "    \n",
    "    # ========== SECTION 4: Prevalence with C0 ==========\n",
    "    results.append({\n",
    "        'Variable': '=== CARIES PREVALENCE (INCLUDING C0) ===',\n",
    "        'Category': '',\n",
    "        **{abuse: '' for abuse in abuse_types},\n",
    "        'Total': '',\n",
    "        'p-value': ''\n",
    "    })\n",
    "    \n",
    "    # Percentage with DMFT_C0 > 0\n",
    "    if 'DMFT_C0' in df.columns:\n",
    "        row_c0_prev = {'Variable': 'Children with Caries (incl. C0)', 'Category': 'DMFT_C0 > 0'}\n",
    "        \n",
    "        for abuse in abuse_types:\n",
    "            subset = df[df['abuse'] == abuse]\n",
    "            n_total = len(subset)\n",
    "            n_caries = (subset['DMFT_C0'] > 0).sum()\n",
    "            pct = (n_caries / n_total * 100) if n_total > 0 else 0\n",
    "            row_c0_prev[abuse] = f\"{n_caries}/{n_total} ({pct:.1f}%)\"\n",
    "        \n",
    "        n_total_all = len(df)\n",
    "        n_caries_all = (df['DMFT_C0'] > 0).sum()\n",
    "        pct_all = (n_caries_all / n_total_all * 100) if n_total_all > 0 else 0\n",
    "        row_c0_prev['Total'] = f\"{n_caries_all}/{n_total_all} ({pct_all:.1f}%)\"\n",
    "        \n",
    "        # Chi-square test\n",
    "        df['has_caries_c0'] = (df['DMFT_C0'] > 0).astype(int)\n",
    "        contingency_c0 = pd.crosstab(df['abuse'], df['has_caries_c0'])\n",
    "        try:\n",
    "            chi2, p_val, _, _ = chi2_contingency(contingency_c0)\n",
    "            row_c0_prev['p-value'] = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "        except:\n",
    "            row_c0_prev['p-value'] = 'N/A'\n",
    "        results.append(row_c0_prev)\n",
    "\n",
    "    # ========== SECTION 5: Post-hoc Dunn's Tests for C0 variables ==========\n",
    "    results.append({\n",
    "        'Variable': '=== POST-HOC pairwise (Dunn\\'s) ===',\n",
    "        'Category': '(Only if KW p < 0.05)',\n",
    "        **{abuse: '' for abuse in abuse_types},\n",
    "        'Total': '',\n",
    "        'p-value': ''\n",
    "    })\n",
    "\n",
    "    for var_name, var_label in c0_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Re-check KW p-value\n",
    "        groups = [df[df['abuse'] == abuse][var_name].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            _, kw_p = kruskal(*groups)\n",
    "            if kw_p >= 0.05:\n",
    "                continue\n",
    "                \n",
    "            dunn_result = posthoc_dunn(df, val_col=var_name, group_col='abuse', p_adjust='bonferroni')\n",
    "            \n",
    "            for i, abuse1 in enumerate(abuse_types):\n",
    "                for abuse2 in abuse_types[i+1:]:\n",
    "                    if abuse1 in dunn_result.index and abuse2 in dunn_result.columns:\n",
    "                        p_val = dunn_result.loc[abuse1, abuse2]\n",
    "                        if p_val < 0.05:\n",
    "                            results.append({\n",
    "                                'Variable': f\"Post-hoc: {var_label}\",\n",
    "                                'Category': f\"{abuse1} vs {abuse2}\",\n",
    "                                **{abuse: (f\"p={p_val:.4f}\" if abuse == abuse1 or abuse == abuse2 else '') for abuse in abuse_types},\n",
    "                                'Total': 'Significant',\n",
    "                                'p-value': f\"{p_val:.4f}\"\n",
    "                            })\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    table5_5 = pd.DataFrame(results)\n",
    "    \n",
    "    tidy_posthoc = []\n",
    "    for var_name, var_label in c0_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "        groups = [df[df['abuse'] == abuse][var_name].dropna() for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            _, kw_p = kruskal(*groups)\n",
    "            if kw_p < 0.05:\n",
    "                dunn_adj, dunn_unadj = posthoc_dunn(df, val_col=var_name, group_col='abuse', p_adjust='bonferroni')\n",
    "                for i, abuse1 in enumerate(abuse_types):\n",
    "                    for abuse2 in abuse_types[i+1:]:\n",
    "                        if abuse1 in dunn_adj.index and abuse2 in dunn_adj.columns:\n",
    "                            tidy_posthoc.append({\n",
    "                                'analysis_type': 'Table 5.5: C0 Stats',\n",
    "                                'variable': var_name,\n",
    "                                'group1': abuse1,\n",
    "                                'group2': abuse2,\n",
    "                                'p_unadjusted': dunn_unadj.loc[abuse1, abuse2],\n",
    "                                'p_adjusted': dunn_adj.loc[abuse1, abuse2],\n",
    "                                'significant': dunn_adj.loc[abuse1, abuse2] < 0.05\n",
    "                            })\n",
    "        except: pass\n",
    "\n",
    "    return table5_5, tidy_posthoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc077f7",
   "metadata": {},
   "source": [
    "#### Table : DMFT by Dentition Type and Abuse Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table6_dmft_by_dentition_abuse(df):\n",
    "    \"\"\"\n",
    "    Table 6: DMFT_Index analysis by dentition type and abuse type\n",
    "    \n",
    "    Groups based on present teeth:\n",
    "    - primary_dentition: Present_Baby_Teeth == Present_Teeth (only baby teeth present)\n",
    "    - permanent_dentition: Present_Perm_Teeth == Present_Teeth (only permanent teeth present)\n",
    "    - mixed_dentition: Both baby and permanent teeth present\n",
    "    \n",
    "    Returns a DataFrame with descriptive statistics for each dentition_type × abuse combination\n",
    "    \"\"\"\n",
    "    required_cols = ['DMFT_Index', 'Present_Teeth', 'Present_Baby_Teeth', 'Present_Perm_Teeth', 'abuse']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"   ⚠ '{col}' column not found in data\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    # Create dentition type groups based on present teeth\n",
    "    df_analysis = df.copy()\n",
    "    \n",
    "    def get_dentition_type(row):\n",
    "        present_teeth = row['Present_Teeth'] if pd.notna(row['Present_Teeth']) else 0\n",
    "        present_baby = row['Present_Baby_Teeth'] if pd.notna(row['Present_Baby_Teeth']) else 0\n",
    "        present_perm = row['Present_Perm_Teeth'] if pd.notna(row['Present_Perm_Teeth']) else 0\n",
    "        \n",
    "        if present_teeth == 0:\n",
    "            return 'No_Teeth'\n",
    "        elif present_baby == present_teeth and present_perm == 0:\n",
    "            return 'primary_dentition'\n",
    "        elif present_perm == present_teeth and present_baby == 0:\n",
    "            return 'permanent_dentition'\n",
    "        else:\n",
    "            return 'mixed_dentition'\n",
    "    \n",
    "    df_analysis['dentition_type'] = df_analysis.apply(get_dentition_type, axis=1)\n",
    "    \n",
    "    abuse_types = list(df['abuse'].cat.categories)\n",
    "    dentition_order = ['primary_dentition', 'mixed_dentition', 'permanent_dentition']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for dent_type in dentition_order:\n",
    "        df_dent = df_analysis[df_analysis['dentition_type'] == dent_type]\n",
    "        \n",
    "        if len(df_dent) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Kruskal-Wallis test across abuse types within this dentition type\n",
    "        groups = [df_dent[df_dent['abuse'] == abuse]['DMFT_Index'].dropna() \n",
    "                  for abuse in abuse_types]\n",
    "        groups = [g for g in groups if len(g) > 0]\n",
    "        \n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                h_stat, p_kw = kruskal(*groups)\n",
    "                p_val_str = f\"{p_kw:.4f}\" if p_kw >= 0.0001 else \"<0.0001\"\n",
    "            except:\n",
    "                p_val_str = \"N/A\"\n",
    "        else:\n",
    "            p_val_str = \"N/A\"\n",
    "        \n",
    "        first_row = True\n",
    "        for abuse in abuse_types:\n",
    "            subset = df_dent[(df_dent['abuse'] == abuse)]['DMFT_Index'].dropna()\n",
    "            \n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            row = {\n",
    "                'Dentition_Type': dent_type if first_row else '',\n",
    "                'Abuse_Type': abuse,\n",
    "                'N': len(subset),\n",
    "                'Mean': f\"{subset.mean():.2f}\",\n",
    "                'SD': f\"{subset.std():.2f}\",\n",
    "                'Median': f\"{subset.median():.1f}\",\n",
    "                '25%': f\"{subset.quantile(0.25):.1f}\",\n",
    "                '75%': f\"{subset.quantile(0.75):.1f}\",\n",
    "                'Min': f\"{subset.min():.0f}\",\n",
    "                'Max': f\"{subset.max():.0f}\",\n",
    "                'p-value (KW)': p_val_str if first_row else ''\n",
    "            }\n",
    "            results.append(row)\n",
    "            first_row = False\n",
    "    \n",
    "    # ========== SUMMARY SECTION ==========\n",
    "    # Add separator\n",
    "    results.append({\n",
    "        'Dentition_Type': '=== SUMMARY BY DENTITION TYPE ===',\n",
    "        'Abuse_Type': '',\n",
    "        'N': '',\n",
    "        'Mean': '',\n",
    "        'SD': '',\n",
    "        'Median': '',\n",
    "        '25%': '',\n",
    "        '75%': '',\n",
    "        'Min': '',\n",
    "        'Max': '',\n",
    "        'p-value (KW)': ''\n",
    "    })\n",
    "    \n",
    "    # Kruskal-Wallis test across dentition types (overall)\n",
    "    dent_groups = [df_analysis[df_analysis['dentition_type'] == dt]['DMFT_Index'].dropna() \n",
    "                   for dt in dentition_order]\n",
    "    dent_groups = [g for g in dent_groups if len(g) > 0]\n",
    "    \n",
    "    if len(dent_groups) >= 2:\n",
    "        try:\n",
    "            h_stat, p_kw_overall = kruskal(*dent_groups)\n",
    "            p_kw_overall_str = f\"{p_kw_overall:.4f}\" if p_kw_overall >= 0.0001 else \"<0.0001\"\n",
    "        except:\n",
    "            p_kw_overall_str = \"N/A\"\n",
    "    else:\n",
    "        p_kw_overall_str = \"N/A\"\n",
    "    \n",
    "    # Add descriptive stats for each dentition type (all abuse types combined)\n",
    "    first_summary = True\n",
    "    for dent_type in dentition_order:\n",
    "        subset = df_analysis[df_analysis['dentition_type'] == dent_type]['DMFT_Index'].dropna()\n",
    "        if len(subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        n_total = len(subset)\n",
    "        pct = (n_total / len(df_analysis) * 100) if len(df_analysis) > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Dentition_Type': dent_type,\n",
    "            'Abuse_Type': f'All abuse types (n={n_total}, {pct:.1f}%)',\n",
    "            'N': n_total,\n",
    "            'Mean': f\"{subset.mean():.2f}\",\n",
    "            'SD': f\"{subset.std():.2f}\",\n",
    "            'Median': f\"{subset.median():.1f}\",\n",
    "            '25%': f\"{subset.quantile(0.25):.1f}\",\n",
    "            '75%': f\"{subset.quantile(0.75):.1f}\",\n",
    "            'Min': f\"{subset.min():.0f}\",\n",
    "            'Max': f\"{subset.max():.0f}\",\n",
    "            'p-value (KW)': f\"Overall KW: {p_kw_overall_str}\" if first_summary else ''\n",
    "        })\n",
    "        first_summary = False\n",
    "    \n",
    "    # Pairwise Mann-Whitney U tests between dentition types\n",
    "    results.append({\n",
    "        'Dentition_Type': '--- Pairwise Comparisons (Dunn\\'s Test with Bonferroni) ---',\n",
    "        'Abuse_Type': '',\n",
    "        'N': '',\n",
    "        'Mean': '',\n",
    "        'SD': '',\n",
    "        'Median': '',\n",
    "        '25%': '',\n",
    "        '75%': '',\n",
    "        'Min': '',\n",
    "        'Max': '',\n",
    "        'p-value (KW)': ''\n",
    "    })\n",
    "    \n",
    "    # Perform Dunn's test for pairwise comparisons\n",
    "    try:\n",
    "        dunn_results = sp.posthoc_dunn(\n",
    "            df_analysis[df_analysis['dentition_type'].isin(dentition_order)],\n",
    "            val_col='DMFT_Index',\n",
    "            group_col='dentition_type',\n",
    "            p_adjust='bonferroni'\n",
    "        )\n",
    "        \n",
    "        dentition_pairs = list(itertools.combinations(dentition_order, 2))\n",
    "        \n",
    "        for dent1, dent2 in dentition_pairs:\n",
    "            if dent1 in dunn_results.index and dent2 in dunn_results.columns:\n",
    "                p_val = dunn_results.loc[dent1, dent2]\n",
    "                \n",
    "                # Get sample sizes and medians\n",
    "                data1 = df_analysis[df_analysis['dentition_type'] == dent1]['DMFT_Index'].dropna()\n",
    "                data2 = df_analysis[df_analysis['dentition_type'] == dent2]['DMFT_Index'].dropna()\n",
    "                \n",
    "                # Significance stars\n",
    "                if p_val <= 0.001:\n",
    "                    sig = '***'\n",
    "                elif p_val <= 0.01:\n",
    "                    sig = '**'\n",
    "                elif p_val <= 0.05:\n",
    "                    sig = '*'\n",
    "                else:\n",
    "                    sig = ''\n",
    "                \n",
    "                p_str = f\"{p_val:.4f}\" if p_val >= 0.0001 else \"<0.0001\"\n",
    "                \n",
    "                results.append({\n",
    "                    'Dentition_Type': f'{dent1} vs {dent2}',\n",
    "                    'Abuse_Type': f'Dunn\\'s test{sig}',\n",
    "                    'N': f'{len(data1)} vs {len(data2)}',\n",
    "                    'Mean': '',\n",
    "                    'SD': '',\n",
    "                    'Median': f'{data1.median():.1f} vs {data2.median():.1f}',\n",
    "                    '25%': '',\n",
    "                    '75%': '',\n",
    "                    'Min': '',\n",
    "                    'Max': '',\n",
    "                    'p-value (KW)': f'p={p_str}{sig}'\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠ Dunn's test failed: {e}\")\n",
    "    \n",
    "    table6 = pd.DataFrame(results)\n",
    "    return table6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0febb494",
   "metadata": {},
   "source": [
    "#### Pairwise Mann-Whitney U Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_mannwhitney(df, var_name, group_col='abuse', p_adjust='bonferroni'):\n",
    "    \"\"\"\n",
    "    Perform pairwise Mann-Whitney U tests between all groups.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with data\n",
    "    - var_name: Name of the continuous variable to compare (e.g., 'DMFT_Index')\n",
    "    - group_col: Name of the grouping column (e.g., 'abuse')\n",
    "    - p_adjust: Method for p-value adjustment ('bonferroni' or None)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with pairwise comparison results\n",
    "    \"\"\"\n",
    "    # Get unique groups\n",
    "    if df[group_col].dtype.name == 'category':\n",
    "        groups = df[group_col].cat.categories.tolist()\n",
    "    else:\n",
    "        groups = sorted(df[group_col].dropna().unique())\n",
    "    \n",
    "    # Generate all pairwise combinations\n",
    "    pairs = list(itertools.combinations(groups, 2))\n",
    "    n_comparisons = len(pairs)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for group1, group2 in pairs:\n",
    "        # Get data for each group\n",
    "        data1 = df[df[group_col] == group1][var_name].dropna()\n",
    "        data2 = df[df[group_col] == group2][var_name].dropna()\n",
    "        \n",
    "        if len(data1) == 0 or len(data2) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Perform Mann-Whitney U test\n",
    "        u_stat, p_val = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "        \n",
    "        # Calculate effect size (rank-biserial correlation r)\n",
    "        n1, n2 = len(data1), len(data2)\n",
    "        r = 1 - (2 * u_stat) / (n1 * n2)\n",
    "        \n",
    "        # Adjust p-value if requested\n",
    "        if p_adjust == 'bonferroni':\n",
    "            p_adjusted = min(p_val * n_comparisons, 1.0)\n",
    "        else:\n",
    "            p_adjusted = p_val\n",
    "        \n",
    "        # Format p-value\n",
    "        if p_adjusted < 0.0001:\n",
    "            p_str = '<0.0001'\n",
    "        else:\n",
    "            p_str = f'{p_adjusted:.4f}'\n",
    "        \n",
    "        # Significance stars\n",
    "        if p_adjusted <= 0.001:\n",
    "            sig = '***'\n",
    "        elif p_adjusted <= 0.01:\n",
    "            sig = '**'\n",
    "        elif p_adjusted <= 0.05:\n",
    "            sig = '*'\n",
    "        else:\n",
    "            sig = ''\n",
    "        \n",
    "        results.append({\n",
    "            'Group1': group1,\n",
    "            'Group2': group2,\n",
    "            'N1': n1,\n",
    "            'N2': n2,\n",
    "            'Median1': f'{data1.median():.2f}',\n",
    "            'Median2': f'{data2.median():.2f}',\n",
    "            'U_Statistic': f'{u_stat:.0f}',\n",
    "            'p-value_raw': f'{p_val:.4f}' if p_val >= 0.0001 else '<0.0001',\n",
    "            'p-value_adjusted': p_str,\n",
    "            'Effect_Size_r': f'{r:.3f}',\n",
    "            'Significance': sig\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def analyze_dmft_by_dentition_with_pairwise(df):\n",
    "    \"\"\"\n",
    "    Analyze DMFT by dentition type with pairwise Mann-Whitney U tests.\n",
    "    \n",
    "    Creates 3 groups based on present teeth:\n",
    "    - primary_dentition: Present_Baby_Teeth == Present_Teeth (only baby teeth present)\n",
    "    - permanent_dentition: Present_Perm_Teeth == Present_Teeth (only permanent teeth present)\n",
    "    - mixed_dentition: Both baby and permanent teeth present\n",
    "    \n",
    "    Then performs pairwise Mann-Whitney U tests between abuse types within each group.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with pairwise comparison results for each dentition type\n",
    "    \"\"\"\n",
    "    required_cols = ['DMFT_Index', 'Present_Teeth', 'Present_Baby_Teeth', 'Present_Perm_Teeth', 'abuse']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"   ⚠ '{col}' column not found in data\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    # Create dentition type column based on present teeth\n",
    "    def get_dentition_type(row):\n",
    "        present_teeth = row['Present_Teeth'] if pd.notna(row['Present_Teeth']) else 0\n",
    "        present_baby = row['Present_Baby_Teeth'] if pd.notna(row['Present_Baby_Teeth']) else 0\n",
    "        present_perm = row['Present_Perm_Teeth'] if pd.notna(row['Present_Perm_Teeth']) else 0\n",
    "        \n",
    "        if present_teeth == 0:\n",
    "            return 'No_Teeth'\n",
    "        elif present_baby == present_teeth and present_perm == 0:\n",
    "            return 'primary_dentition'\n",
    "        elif present_perm == present_teeth and present_baby == 0:\n",
    "            return 'permanent_dentition'\n",
    "        else:\n",
    "            return 'mixed_dentition'\n",
    "    \n",
    "    df_analysis = df.copy()\n",
    "    df_analysis['dentition_type'] = df_analysis.apply(get_dentition_type, axis=1)\n",
    "    \n",
    "    dentition_order = ['primary_dentition', 'mixed_dentition', 'permanent_dentition']\n",
    "    all_pairwise_results = []\n",
    "    \n",
    "    for dent_type in dentition_order:\n",
    "        df_subset = df_analysis[df_analysis['dentition_type'] == dent_type]\n",
    "        \n",
    "        if len(df_subset) < 10:  # Skip if too few samples\n",
    "            print(f\"   ⚠ Skipping {dent_type}: only {len(df_subset)} samples\")\n",
    "            continue\n",
    "        \n",
    "        # Perform pairwise Mann-Whitney U tests\n",
    "        pairwise_df = pairwise_mannwhitney(df_subset, 'DMFT_Index', 'abuse', 'bonferroni')\n",
    "        if not pairwise_df.empty:\n",
    "            pairwise_df.insert(0, 'Dentition_Type', dent_type)\n",
    "            all_pairwise_results.append(pairwise_df)\n",
    "    \n",
    "    if all_pairwise_results:\n",
    "        return pd.concat(all_pairwise_results, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3c907",
   "metadata": {},
   "source": [
    "#### 可視化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ci(ci_str):\n",
    "    \"\"\"95% CI文字列からlowerとupperを抽出\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'\\(([\\d.]+)-([\\d.]+)\\)', ci_str)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    return np.nan, np.nan\n",
    "\n",
    "\n",
    "def create_forest_plot_vertical(df_logistic, df_original, output_dir, timestamp, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    縦型フォレストプロット（ロジスティック回帰結果の可視化）\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_logistic : DataFrame\n",
    "        ロジスティック回帰の結果（Table4）\n",
    "    df_original : DataFrame\n",
    "        元のデータフレーム（サンプルサイズ計算用）\n",
    "    output_dir : str\n",
    "        出力ディレクトリ\n",
    "    timestamp : str\n",
    "        タイムスタンプ\n",
    "    figsize : tuple\n",
    "        図のサイズ\n",
    "    \"\"\"\n",
    "    import matplotlib.patches as mpatches\n",
    "    \n",
    "    df = df_logistic.copy()\n",
    "    \n",
    "    # N/Aを含む行を除外\n",
    "    df = df[df['Odds Ratio'] != 'N/A']\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"   ⚠ No valid data for forest plot\")\n",
    "        return\n",
    "    \n",
    "    # オッズ比を数値に変換\n",
    "    df['OR'] = pd.to_numeric(df['Odds Ratio'], errors='coerce')\n",
    "    \n",
    "    # CIの解析\n",
    "    df[['CI_lower', 'CI_upper']] = df['95% CI'].apply(\n",
    "        lambda x: pd.Series(parse_ci(x))\n",
    "    )\n",
    "    \n",
    "    # p値を数値に変換するヘルパー関数\n",
    "    def parse_p_value(x):\n",
    "        \"\"\"Convert p-value string to numeric value.\"\"\"\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if x == '<0.0001':\n",
    "            return 0.0001\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (ValueError, TypeError):\n",
    "            return np.nan\n",
    "    \n",
    "    # p値をフォーマットするヘルパー関数\n",
    "    def format_p_value(p):\n",
    "        \"\"\"\n",
    "        Format p-value with significance stars.\n",
    "        *** p ≤ 0.001\n",
    "        **  p ≤ 0.01\n",
    "        *   p ≤ 0.05\n",
    "        \"\"\"\n",
    "        if pd.isna(p):\n",
    "            return ''\n",
    "        if p <= 0.001:\n",
    "            return '≤0.001***'\n",
    "        elif p <= 0.01:\n",
    "            return f'{p:.3f}**'\n",
    "        elif p <= 0.05:\n",
    "            return f'{p:.2f}*'\n",
    "        else:\n",
    "            return f'{p:.2f}'\n",
    "    \n",
    "    # p値を数値に変換\n",
    "    df['p_numeric'] = df['p-value'].apply(parse_p_value)\n",
    "    \n",
    "    # p値をフォーマット（有意性の星印付き）\n",
    "    df['p_formatted'] = df['p_numeric'].apply(format_p_value)\n",
    "    \n",
    "    # 有意性のフラグ\n",
    "    df['significant'] = df['p_numeric'] < 0.05\n",
    "    \n",
    "    # アウトカムの順序\n",
    "    outcome_order = df['Outcome'].unique()\n",
    "    \n",
    "    # 比較群の色（カラーブラインドフレンドリー: Wong palette）\n",
    "    # https://www.nature.com/articles/nmeth.1618\n",
    "    comparison_colors = {\n",
    "        'Neglect vs Physical Abuse': '#E69F00',           # Orange\n",
    "        'Emotional Abuse vs Physical Abuse': '#56B4E9',   # Sky Blue  \n",
    "        'Sexual Abuse vs Physical Abuse': '#009E73'       # Bluish Green\n",
    "    }\n",
    "    \n",
    "    # サンプルサイズを計算\n",
    "    abuse_sample_sizes = {}\n",
    "    for abuse in ['Physical Abuse', 'Neglect', 'Emotional Abuse', 'Sexual Abuse']:\n",
    "        abuse_sample_sizes[abuse] = len(df_original[df_original['abuse'] == abuse])\n",
    "    \n",
    "    # 比較群のサンプルサイズラベル\n",
    "    comparison_n = {\n",
    "        'Neglect': f\"Neglect\\n(n={abuse_sample_sizes['Neglect']})\",\n",
    "        'Emotional Abuse': f\"Emotional Abuse\\n(n={abuse_sample_sizes['Emotional Abuse']})\",\n",
    "        'Sexual Abuse': f\"Sexual Abuse\\n(n={abuse_sample_sizes['Sexual Abuse']})\"\n",
    "    }\n",
    "    \n",
    "    # プロット作成\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Y軸の位置を計算\n",
    "    y_positions = []\n",
    "    y_labels = []\n",
    "    y_pos = 0\n",
    "    outcome_positions = {}\n",
    "    \n",
    "    for outcome in outcome_order:\n",
    "        outcome_data = df[df['Outcome'] == outcome]\n",
    "        outcome_positions[outcome] = []\n",
    "        \n",
    "        for _, row in outcome_data.iterrows():\n",
    "            y_positions.append(y_pos)\n",
    "            # サンプルサイズ付きラベル\n",
    "            comparison_short = row['Comparison'].replace(' vs Physical Abuse', '')\n",
    "            label_with_n = comparison_n.get(comparison_short, comparison_short)\n",
    "            y_labels.append(label_with_n)\n",
    "            outcome_positions[outcome].append(y_pos)\n",
    "            y_pos += 1\n",
    "        \n",
    "        y_pos += 0.5  # アウトカム間のスペース\n",
    "    \n",
    "    # 参照線（OR=1）\n",
    "    ax.axvline(x=1, color='black', linestyle='--', linewidth=1, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # エラーバーとポイントのプロット\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        y = y_positions[i]\n",
    "        or_val = row['OR']\n",
    "        ci_low = row['CI_lower']\n",
    "        ci_up = row['CI_upper']\n",
    "        \n",
    "        # 色の選択\n",
    "        color = comparison_colors.get(row['Comparison'], '#3498db')\n",
    "        \n",
    "        # マーカーサイズ（有意な場合は大きく）\n",
    "        marker_size = 150 if row['significant'] else 100\n",
    "        marker = 's' if row['significant'] else 'o'\n",
    "        \n",
    "        # エラーバー\n",
    "        ax.errorbar(or_val, y, xerr=[[or_val - ci_low], [ci_up - or_val]], \n",
    "                   fmt='none', color=color, capsize=4, capthick=2, linewidth=2, zorder=2)\n",
    "        \n",
    "        # ポイント\n",
    "        ax.scatter(or_val, y, s=marker_size, c=color, marker=marker, \n",
    "                  edgecolors='white', linewidth=1.5, zorder=3)\n",
    "        \n",
    "        # OR値とCI、p値のテキスト\n",
    "        text_x = max(ci_up + 0.1, 2.5)\n",
    "        or_text = f\"{or_val:.2f} ({ci_low:.2f}-{ci_up:.2f})\"\n",
    "        # Use 'p' instead of 'p=' when formatted value starts with '≤'\n",
    "        p_formatted = row['p_formatted']\n",
    "        p_text = f\"p{p_formatted}\" if p_formatted.startswith('≤') else f\"p={p_formatted}\"\n",
    "        \n",
    "        ax.annotate(or_text, xy=(text_x, y), fontsize=9, va='center')\n",
    "        ax.annotate(p_text, xy=(text_x + 1.2, y), fontsize=8, va='center', \n",
    "                   color='red' if row['significant'] else 'gray')\n",
    "    \n",
    "    # アウトカムラベル（左側に追加）\n",
    "    for outcome in outcome_order:\n",
    "        positions = outcome_positions[outcome]\n",
    "        if positions:\n",
    "            mid_y = np.mean(positions)\n",
    "            ax.annotate(outcome, xy=(-0.3, mid_y), fontsize=11, fontweight='bold',\n",
    "                       va='center', ha='right', \n",
    "                       xycoords=('axes fraction', 'data'))\n",
    "            \n",
    "            # アウトカム間の区切り線\n",
    "            if outcome != list(outcome_order)[-1]:\n",
    "                max_y = max(positions)\n",
    "                ax.axhline(y=max_y + 0.25, color='lightgray', linestyle='-', \n",
    "                          linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Y軸の設定\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(y_labels, fontsize=10)\n",
    "    ax.invert_yaxis()  # 上から下へ\n",
    "    \n",
    "    # X軸の設定\n",
    "    ax.set_xlabel('Odds Ratio (95% CI)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlim(0, 4.5)\n",
    "    \n",
    "    # タイトル（参照群のサンプルサイズも表示）\n",
    "    ax.set_title(f'Adjusted Odds Ratios by Abuse Type\\n(Reference: Physical Abuse n={abuse_sample_sizes[\"Physical Abuse\"]}, Adjusted for Age and Sex)', \n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # # 凡例\n",
    "    # legend_elements = [\n",
    "    #     mpatches.Patch(color=comparison_colors['Neglect vs Physical Abuse'], \n",
    "    #                   label='Neglect'),\n",
    "    #     mpatches.Patch(color=comparison_colors['Emotional Abuse vs Physical Abuse'], \n",
    "    #                   label='Emotional Abuse'),\n",
    "    #     mpatches.Patch(color=comparison_colors['Sexual Abuse vs Physical Abuse'], \n",
    "    #                   label='Sexual Abuse'),\n",
    "    # ]\n",
    "    # ax.legend(handles=legend_elements, loc='upper right', framealpha=0.9, fontsize=10)\n",
    "    \n",
    "    # グリッド\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle=':')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # 枠線の調整\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存\n",
    "    output_path_png = f'{output_dir}figure_forest_plot_{timestamp}.png'\n",
    "    output_path_tiff = f'{output_dir}figure_forest_plot_{timestamp}.tiff'\n",
    "    \n",
    "    plt.savefig(output_path_png, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(output_path_tiff, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   ✓ Forest plot saved: figure_forest_plot_{timestamp}.png\")\n",
    "    print(f\"   ✓ Forest plot saved: figure_forest_plot_{timestamp}.tiff\")\n",
    "\n",
    "\n",
    "def create_visualizations(df, output_dir):\n",
    "    \"\"\"\n",
    "    論文用の図を作成\n",
    "    \"\"\"\n",
    "    abuse_order = [\"Physical Abuse\", \"Neglect\", \"Emotional Abuse\", \"Sexual Abuse\"]\n",
    "    # カラーブラインドフレンドリー配色（Wong palette）\n",
    "    colors = ['#0072B2', '#E69F00', '#56B4E9', '#009E73']  # Blue, Orange, Sky Blue, Bluish Green\n",
    "    \n",
    "    df_plot = df[df['abuse'].isin(abuse_order)].copy()\n",
    "    \n",
    "    # サンプルサイズを計算\n",
    "    sample_sizes = {abuse: len(df_plot[df_plot['abuse'] == abuse]) for abuse in abuse_order}\n",
    "    \n",
    "    # サンプルサイズ付きラベルを作成\n",
    "    abuse_labels_with_n = [f\"{abuse}\\n(n={sample_sizes[abuse]})\" for abuse in abuse_order]\n",
    "    \n",
    "    if 'DMFT_Index' in df.columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        sns.boxplot(x='abuse', y='DMFT_Index', data=df_plot, \n",
    "                    order=abuse_order, palette=colors, ax=ax)\n",
    "        \n",
    "        ax.set_xlabel('Abuse Type', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('DMFT Index', fontsize=14, fontweight='bold')\n",
    "        ax.set_title('Distribution of DMFT Index by Abuse Type', fontsize=16, fontweight='bold')\n",
    "        ax.set_xticklabels(abuse_labels_with_n, fontsize=10)\n",
    "        # ax.tick_params(axis='x', rotation=15)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}figure1_dmft_boxplot.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(x='abuse', y='age_year', data=df_plot,\n",
    "                   order=abuse_order, palette=colors, ax=ax)\n",
    "    \n",
    "    ax.set_xlabel('Abuse Type', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Age (years)', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Age Distribution by Abuse Type', fontsize=16, fontweight='bold')\n",
    "    ax.set_xticklabels(abuse_labels_with_n, fontsize=10)\n",
    "    # ax.tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}figure2_age_violin.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    oral_vars = ['DMFT_Index', 'UTN_Score', 'Care_Index', 'Healthy_Rate', 'C0_Count', 'Trauma_Count']\n",
    "    oral_vars_available = [v for v in oral_vars if v in df.columns]\n",
    "    \n",
    "    if len(oral_vars_available) > 0:\n",
    "        mean_by_abuse = df_plot.groupby('abuse', observed=True)[oral_vars_available].mean()\n",
    "        mean_by_abuse = mean_by_abuse.reindex(abuse_order)\n",
    "        \n",
    "        mean_normalized = (mean_by_abuse - mean_by_abuse.mean()) / mean_by_abuse.std()\n",
    "        \n",
    "        # ヒートマップ用のサンプルサイズ付きラベル\n",
    "        heatmap_labels = [f\"{abuse}\\n(n={sample_sizes[abuse]})\" for abuse in abuse_order]\n",
    "        mean_normalized.index = heatmap_labels\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(mean_normalized.T, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
    "                    center=0, ax=ax, cbar_kws={'label': 'Z-score'})\n",
    "        \n",
    "        ax.set_xlabel('Abuse Type', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Oral Health Indicator', fontsize=14, fontweight='bold')\n",
    "        ax.set_title('Standardized Oral Health Indicators by Abuse Type', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}figure3_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    cat_vars = [\n",
    "        ('gingivitis', 'Gingivitis'),\n",
    "        ('needTOBEtreated', 'Treatment Need'),\n",
    "        ('OralCleanStatus', 'Oral Hygiene Status')\n",
    "    ]\n",
    "    \n",
    "    for var_name, var_label in cat_vars:\n",
    "        if var_name not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        df_valid = df_plot.dropna(subset=[var_name])\n",
    "        \n",
    "        # 各カテゴリのサンプルサイズを計算（有効データのみ）\n",
    "        cat_sample_sizes = {abuse: len(df_valid[df_valid['abuse'] == abuse]) for abuse in abuse_order}\n",
    "        cat_labels_with_n = [f\"{abuse}\\n(n={cat_sample_sizes[abuse]})\" for abuse in abuse_order]\n",
    "        \n",
    "        crosstab = pd.crosstab(df_valid['abuse'], df_valid[var_name], normalize='index') * 100\n",
    "        crosstab = crosstab.reindex(abuse_order)\n",
    "        \n",
    "        crosstab.plot(kind='bar', ax=ax, width=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Abuse Type', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "        ax.set_title(f'{var_label} Distribution by Abuse Type', fontsize=16, fontweight='bold')\n",
    "        ax.set_xticklabels(cat_labels_with_n, fontsize=10, \n",
    "                        #    rotation=15, \n",
    "                           ha='right')\n",
    "        # ax.legend(title=var_label, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}figure_{var_name}_bar.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"✓ Figures saved to: {output_dir}\")\n",
    "\n",
    "def plot_boxplot_with_dunn(df, var_name, group_col='abuse', title=None, output_dir=OUTPUT_DIR,\n",
    "                           p_adjust='bonferroni', palette='Set2', yaxis_name=None):\n",
    "    \"\"\"\n",
    "    Kruskal-Wallis検定後のDunn検定を行い、有意差があるペアをBoxplot上に描画する関数\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - var_name: 分析対象の連続変数名 (例: 'DMFT_Index')\n",
    "    - group_col: 群分けの変数名 (例: 'abuse')\n",
    "    - title: グラフのタイトル (Noneの場合は変数名を使用)\n",
    "    - p_adjust: Dunn検定の補正方法 ('bonferroni', 'holm' など)\n",
    "    \"\"\"\n",
    "    \n",
    "    # データをドロップ（欠損値除去）\n",
    "    data = df[[group_col, var_name]].dropna()\n",
    "    \n",
    "    # カテゴリの順序を取得（category型の場合）\n",
    "    if data[group_col].dtype.name == 'category':\n",
    "        categories = data[group_col].cat.categories.tolist()\n",
    "    else:\n",
    "        categories = sorted(data[group_col].unique())\n",
    "    \n",
    "    # 1. Dunn's Testの実施\n",
    "    try:\n",
    "        # scikit-posthocsのposthoc_dunnを使用\n",
    "        dunn_results = sp.posthoc_dunn(data, val_col=var_name, group_col=group_col, p_adjust=p_adjust)\n",
    "    except Exception as e:\n",
    "        print(f\"Dunn検定エラー: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Boxplotの描画\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.boxplot(x=group_col, y=var_name, data=data, order=categories, palette=palette, fill=False, legend=False, linewidth=2)\n",
    "    sns.stripplot(x=group_col, y=var_name, data=data, order=categories, jitter=True, alpha=0.5, size=5, color=\".3\")\n",
    "\n",
    "    # 3. 有意差ラインの描画準備\n",
    "    significant_combinations = []\n",
    "    \n",
    "    # Dunn検定の結果から有意なペアを抽出\n",
    "    # マトリックス形式の結果をループ処理\n",
    "    for i, cat1 in enumerate(categories):\n",
    "        for j, cat2 in enumerate(categories):\n",
    "            if i < j: # 重複を避けるため上三角のみ\n",
    "                try:\n",
    "                    p_val = dunn_results.loc[cat1, cat2]\n",
    "                    if p_val < 0.05:\n",
    "                        significant_combinations.append(((cat1, cat2), p_val))\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "    # 有意差ラインを描画するための高さ設定\n",
    "    y_max = data[var_name].max()\n",
    "    y_range = y_max - data[var_name].min()\n",
    "    h_step = y_range * 0.1  # ライン間の高さの間隔（データの10%分）\n",
    "    y_start = y_max + (y_range * 0.05) # 最初のラインの開始位置\n",
    "    \n",
    "    # 有意なペアごとにラインを描画\n",
    "    # 見やすくするために、距離が近いペアから順に書くなどの工夫も可能ですが、今回は単純ループ\n",
    "    for idx, ((cat1, cat2), p_val) in enumerate(significant_combinations):\n",
    "        # x座標の取得\n",
    "        x1 = categories.index(cat1)\n",
    "        x2 = categories.index(cat2)\n",
    "        \n",
    "        # ラインのy座標\n",
    "        y = y_start + (idx * h_step)\n",
    "        h = y_range * 0.02 # フックの高さ\n",
    "        \n",
    "        # ラインとフックの描画\n",
    "        plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c='k')\n",
    "        \n",
    "        # p値のテキスト表示\n",
    "        # p値の表記形式（アスタリスクにするか数値にするか）\n",
    "        if p_val < 0.001:\n",
    "            label = \"***\"\n",
    "        elif p_val < 0.01:\n",
    "            label = \"**\"\n",
    "        elif p_val < 0.05:\n",
    "            label = \"*\"\n",
    "        else:\n",
    "            label = \"ns\"\n",
    "            \n",
    "        # 数値で表示したい場合はこちらを使用: label = f\"p={p_val:.3f}\"\n",
    "        \n",
    "        if np.isfinite(x1) and np.isfinite(x2) and np.isfinite(y) and np.isfinite(h):\n",
    "            plt.text((x1+x2)*.5, y+h, label, ha='center', va='bottom', color='k', fontsize=10)\n",
    "\n",
    "    # グラフの体裁を整える\n",
    "    # ラインを描いた分だけY軸の上限を広げる\n",
    "    if len(significant_combinations) > 0:\n",
    "        plt.ylim(top=y_start + (len(significant_combinations) * h_step) + h_step)\n",
    "    \n",
    "    # abuse_order を使ってループすることで位置ズレを防ぎます\n",
    "    for i, abuse_type in enumerate(categories):\n",
    "        subset = data[data[group_col] == abuse_type][var_name]\n",
    "        mean_val = subset.mean()\n",
    "        \n",
    "        # Draw mean line\n",
    "        ax.hlines(mean_val, i - 0.4, i + 0.4, colors='red', linestyles='--', linewidth=2.5, \n",
    "                label='Mean' if i == 0 else '', zorder=10)\n",
    "        \n",
    "        # Add mean value text\n",
    "        if pd.notna(mean_val) and np.isfinite(mean_val):\n",
    "            ax.text(i + 0.45, mean_val, f'{mean_val:.2f}', fontsize=14, color='red', \n",
    "                    va='center', fontweight='bold')\n",
    "\n",
    "\n",
    "    # 4. Add sample sizes to x-axis labels\n",
    "    # 現在のラベルを取得し、n数を追記\n",
    "    # 順序固定しているため、ラベル取得も安全に行えます\n",
    "    labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    new_labels = [f'{label}\\n(n={len(data[data[group_col] == label])})' for label in labels]\n",
    "    ax.set_xticklabels(new_labels, fontsize=18)\n",
    "\n",
    "    # その他設定\n",
    "    labelSize= 18\n",
    "    ax.tick_params(axis='y', labelsize=labelSize)\n",
    "    ax.tick_params(axis='x', labelsize=labelSize)\n",
    "\n",
    "    FontSize = 23\n",
    "    plt.xlabel('Maltreatment Category', fontsize=FontSize, fontweight='bold')\n",
    "    plt.ylabel(yaxis_name if yaxis_name else var_name, fontsize=FontSize, fontweight='bold')\n",
    "\n",
    "    plt.title(title if title else f'{var_name} by Maltreatment Type (Dunn\\'s Test)')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    # 保存\n",
    "    output_path_png = f'{output_dir}pairwise_results_{var_name}_{timestamp}.png'\n",
    "    output_path_tiff = f'{output_dir}pairwise_results_{var_name}_{timestamp}.tiff'\n",
    "    \n",
    "    plt.savefig(output_path_png, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(output_path_tiff, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   ✓ Pairwise results saved: pairwise_results_{var_name}_{timestamp}.png\")\n",
    "    print(f\"   ✓ Pairwise results saved: pairwise_results_{var_name}_{timestamp}.tiff\")\n",
    "\n",
    "\n",
    "def plot_boxplot_by_dentition_type(df, output_dir=OUTPUT_DIR, p_adjust='bonferroni', palette='Set2'):\n",
    "    \"\"\"\n",
    "    Boxplot of DMFT_Index by dentition type with Dunn's test pairwise comparisons.\n",
    "    \n",
    "    Creates 3 groups based on present teeth:\n",
    "    - primary_dentition: Only baby teeth present\n",
    "    - mixed_dentition: Both baby and permanent teeth present\n",
    "    - permanent_dentition: Only permanent teeth present\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with dental data\n",
    "    - output_dir: Output directory for saving plots\n",
    "    - p_adjust: P-value adjustment method for Dunn's test\n",
    "    - palette: Color palette for boxplots\n",
    "    \"\"\"\n",
    "    required_cols = ['DMFT_Index', 'Present_Teeth', 'Present_Baby_Teeth', 'Present_Perm_Teeth']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"   ⚠ '{col}' column not found in data\")\n",
    "            return\n",
    "    \n",
    "    # Create dentition type column\n",
    "    def get_dentition_type(row):\n",
    "        present_teeth = row['Present_Teeth'] if pd.notna(row['Present_Teeth']) else 0\n",
    "        present_baby = row['Present_Baby_Teeth'] if pd.notna(row['Present_Baby_Teeth']) else 0\n",
    "        present_perm = row['Present_Perm_Teeth'] if pd.notna(row['Present_Perm_Teeth']) else 0\n",
    "        \n",
    "        if present_teeth == 0:\n",
    "            return 'No_Teeth'\n",
    "        elif present_baby == present_teeth and present_perm == 0:\n",
    "            return 'primary_dentition'\n",
    "        elif present_perm == present_teeth and present_baby == 0:\n",
    "            return 'permanent_dentition'\n",
    "        else:\n",
    "            return 'mixed_dentition'\n",
    "    \n",
    "    df_analysis = df.copy()\n",
    "    df_analysis['dentition_type'] = df_analysis.apply(get_dentition_type, axis=1)\n",
    "    \n",
    "    # Filter to only include the 3 dentition types\n",
    "    dentition_order = ['primary_dentition', 'mixed_dentition', 'permanent_dentition']\n",
    "    data = df_analysis[df_analysis['dentition_type'].isin(dentition_order)][['dentition_type', 'DMFT_Index']].dropna()\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        print(\"   ⚠ No data available for plotting\")\n",
    "        return\n",
    "    \n",
    "    # 1. Dunn's Test\n",
    "    try:\n",
    "        dunn_results = sp.posthoc_dunn(data, val_col='DMFT_Index', group_col='dentition_type', p_adjust=p_adjust)\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠ Dunn's test error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. Create boxplot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.boxplot(x='dentition_type', y='DMFT_Index', data=data, order=dentition_order, \n",
    "                     palette=palette, fill=False, legend=False, linewidth=2)\n",
    "    sns.stripplot(x='dentition_type', y='DMFT_Index', data=data, order=dentition_order, \n",
    "                  jitter=True, alpha=0.5, size=5, color=\".3\")\n",
    "    \n",
    "    # 3. Extract significant pairs\n",
    "    significant_combinations = []\n",
    "    for i, cat1 in enumerate(dentition_order):\n",
    "        for j, cat2 in enumerate(dentition_order):\n",
    "            if i < j:\n",
    "                try:\n",
    "                    p_val = dunn_results.loc[cat1, cat2]\n",
    "                    if p_val < 0.05:\n",
    "                        significant_combinations.append(((cat1, cat2), p_val))\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # 4. Draw significance lines\n",
    "    y_max = data['DMFT_Index'].max()\n",
    "    y_range = y_max - data['DMFT_Index'].min()\n",
    "    h_step = y_range * 0.1\n",
    "    y_start = y_max + (y_range * 0.05)\n",
    "    \n",
    "    for idx, ((cat1, cat2), p_val) in enumerate(significant_combinations):\n",
    "        x1 = dentition_order.index(cat1)\n",
    "        x2 = dentition_order.index(cat2)\n",
    "        \n",
    "        y = y_start + (idx * h_step)\n",
    "        h = y_range * 0.02\n",
    "        \n",
    "        plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c='k')\n",
    "        \n",
    "        # Significance stars\n",
    "        if p_val < 0.001:\n",
    "            label = \"***\"\n",
    "        elif p_val < 0.01:\n",
    "            label = \"**\"\n",
    "        elif p_val < 0.05:\n",
    "            label = \"*\"\n",
    "        else:\n",
    "            label = \"ns\"\n",
    "        \n",
    "        if np.isfinite(x1) and np.isfinite(x2) and np.isfinite(y) and np.isfinite(h):\n",
    "            plt.text((x1+x2)*.5, y+h, label, ha='center', va='bottom', color='k', fontsize=12)\n",
    "    \n",
    "    # Adjust y-axis limit\n",
    "    if len(significant_combinations) > 0:\n",
    "        plt.ylim(top=y_start + (len(significant_combinations) * h_step) + h_step)\n",
    "    \n",
    "    # 5. Add mean lines\n",
    "    for i, dent_type in enumerate(dentition_order):\n",
    "        subset = data[data['dentition_type'] == dent_type]['DMFT_Index']\n",
    "        mean_val = subset.mean()\n",
    "        \n",
    "        ax.hlines(mean_val, i - 0.4, i + 0.4, colors='red', linestyles='--', linewidth=2.5, \n",
    "                  label='Mean' if i == 0 else '', zorder=10)\n",
    "        \n",
    "        if pd.notna(mean_val) and np.isfinite(mean_val):\n",
    "            ax.text(i + 0.45, mean_val, f'{mean_val:.2f}', fontsize=14, color='red', \n",
    "                    va='center', fontweight='bold')\n",
    "    \n",
    "    # 6. Update x-axis labels with sample sizes\n",
    "    dentition_labels = {\n",
    "        'primary_dentition': 'Primary\\nDentition',\n",
    "        'mixed_dentition': 'Mixed\\nDentition',\n",
    "        'permanent_dentition': 'Permanent\\nDentition'\n",
    "    }\n",
    "    new_labels = [f\"{dentition_labels[dt]}\\n(n={len(data[data['dentition_type'] == dt])})\" \n",
    "                  for dt in dentition_order]\n",
    "    ax.set_xticklabels(new_labels, fontsize=16)\n",
    "    \n",
    "    # 7. Styling\n",
    "    labelSize = 18\n",
    "    ax.tick_params(axis='y', labelsize=labelSize)\n",
    "    ax.tick_params(axis='x', labelsize=labelSize)\n",
    "    \n",
    "    FontSize = 23\n",
    "    plt.xlabel('Dentition Type', fontsize=FontSize, fontweight='bold')\n",
    "    plt.ylabel('DMFT Index', fontsize=FontSize, fontweight='bold')\n",
    "    plt.title(\"DMFT Index by Dentition Type (Dunn's Test with Bonferroni)\", fontsize=20, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    output_path_png = f'{output_dir}pairwise_results_dentition_type_{timestamp}.png'\n",
    "    output_path_tiff = f'{output_dir}pairwise_results_dentition_type_{timestamp}.tiff'\n",
    "    \n",
    "    plt.savefig(output_path_png, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(output_path_tiff, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   ✓ Dentition type plot saved: pairwise_results_dentition_type_{timestamp}.png\")\n",
    "    print(f\"   ✓ Dentition type plot saved: pairwise_results_dentition_type_{timestamp}.tiff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad1013",
   "metadata": {},
   "source": [
    "### メイン実行関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05593377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_analysis(filepath, output_dir=OUTPUT_DIR, timestamp=timestamp):\n",
    "    \"\"\"\n",
    "    完全な解析を実行\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"虐待分類と口腔内状況の関連に関する解析\")\n",
    "    print(\"Analysis of Oral Health Conditions by Child Abuse Type\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    print(\"1. Loading and preparing data...\")\n",
    "    df = load_and_prepare_data(filepath)\n",
    "    print(f\"   Total samples: {len(df)}\")\n",
    "    print(f\"   Abuse types: {df['abuse'].value_counts().to_dict()}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"2. Creating Table 1: Demographic Characteristics...\")\n",
    "    table1 = create_table1_demographics(df)\n",
    "    table1.to_csv(f'{output_dir}table1_demographics_{timestamp}.csv', index=False)\n",
    "    print(f\"   ✓ Saved: table1_demographics_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"3. Creating Table 2: Oral Health Descriptive Statistics...\")\n",
    "    table2_cont, table2_cat = create_table2_oral_health_descriptive(df)\n",
    "    table2_cont.to_csv(f'{output_dir}table2_continuous_{timestamp}.csv', index=False)\n",
    "    table2_cat.to_csv(f'{output_dir}table2_categorical_{timestamp}.csv', index=False)\n",
    "    print(f\"   ✓ Saved: table2_continuous_{timestamp}.csv\")\n",
    "    print(f\"   ✓ Saved: table2_categorical_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"4. Creating Table 3: Statistical Comparisons...\")\n",
    "    table3_overall, table3_posthoc, table3_pairwise, table3_tidy_posthoc = create_table3_statistical_comparisons(df)\n",
    "    table3_overall.to_csv(f'{output_dir}table3_overall_tests_{timestamp}.csv', index=False)\n",
    "    table3_posthoc.to_csv(f'{output_dir}table3_posthoc_{timestamp}.csv', index=False)\n",
    "    table3_pairwise.to_csv(f'{output_dir}table3_pairwise_{timestamp}.csv', index=False)\n",
    "    \n",
    "    print(f\"   ✓ Saved: table3_overall_tests_{timestamp}.csv\")\n",
    "    print(f\"   ✓ Saved: table3_posthoc_{timestamp}.csv\")\n",
    "    print(f\"   ✓ Saved: table3_pairwise_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5. Creating Table 4: Multivariate Analysis...\")\n",
    "    table4 = create_table4_multivariate_analysis(df)\n",
    "    table4.to_csv(f'{output_dir}table4_logistic_regression_{timestamp}.csv', index=False)\n",
    "    print(f\"   ✓ Saved: table4_logistic_regression_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5.1 Creating Forest Plot for Logistic Regression Results...\")\n",
    "    create_forest_plot_vertical(table4, df, output_dir, timestamp)\n",
    "    print()\n",
    "    \n",
    "    print(\"5.2 Creating Table 5: DMFT by Life Stage and Abuse Type...\")\n",
    "    table5, table5_tidy_posthoc = create_table5_dmft_by_lifestage_abuse(df)\n",
    "    if not table5.empty:\n",
    "        table5.to_csv(f'{output_dir}table5_dmft_lifestage_abuse_{timestamp}.csv', index=False)\n",
    "        print(f\"   ✓ Saved: table5_dmft_lifestage_abuse_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5.2.5 Creating Table 5.5: Caries Prevalence and Treatment Status...\")\n",
    "    table5_5, table5_5_tidy_posthoc = create_table5_5_caries_prevalence_treatment(df)\n",
    "    if not table5_5.empty:\n",
    "        table5_5.to_csv(f'{output_dir}table5_5_caries_prevalence_treatment_{timestamp}.csv', index=False)\n",
    "        print(f\"   ✓ Saved: table5_5_caries_prevalence_treatment_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    # Consolidate all tidy post-hoc results\n",
    "    all_tidy_posthoc = table3_tidy_posthoc + table5_tidy_posthoc + table5_5_tidy_posthoc\n",
    "    if all_tidy_posthoc:\n",
    "        consolidated_df = pd.DataFrame(all_tidy_posthoc)\n",
    "        consolidated_df.to_csv(f'{output_dir}posthoc_pairwise_consolidated_summary_{timestamp}.csv', index=False)\n",
    "        print(f\"   ✓ Saved: posthoc_pairwise_consolidated_summary_{timestamp}.csv\")\n",
    "    \n",
    "    print(\"5.3 Creating Table 6: DMFT by Dentition Type and Abuse Type...\")\n",
    "    table6 = create_table6_dmft_by_dentition_abuse(df)\n",
    "    if not table6.empty:\n",
    "        table6.to_csv(f'{output_dir}table6_dmft_dentition_abuse_{timestamp}.csv', index=False)\n",
    "        print(f\"   ✓ Saved: table6_dmft_dentition_abuse_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5.4 Creating Pairwise Mann-Whitney U Tests by Dentition Type...\")\n",
    "    table7 = analyze_dmft_by_dentition_with_pairwise(df)\n",
    "    if not table7.empty:\n",
    "        table7.to_csv(f'{output_dir}table7_pairwise_mannwhitney_dentition_{timestamp}.csv', index=False)\n",
    "        print(f\"   ✓ Saved: table7_pairwise_mannwhitney_dentition_{timestamp}.csv\")\n",
    "    print()\n",
    "    \n",
    "    print(\"6. Creating visualizations...\")\n",
    "    create_visualizations(df, output_dir)\n",
    "    print()\n",
    "\n",
    "    print(\"6.1 Creating Pairwise Results...\")\n",
    "    plot_boxplot_with_dunn(df, 'DMFT_Index', group_col='abuse', yaxis_name='dmft&DMFT Index')\n",
    "    plot_boxplot_with_dunn(df, 'Baby_DMFT', group_col='abuse', yaxis_name='Baby DMFT')\n",
    "    plot_boxplot_with_dunn(df, 'Baby_d', group_col='abuse', yaxis_name='Baby d')\n",
    "    plot_boxplot_with_dunn(df, 'Healthy_Rate', group_col='abuse', yaxis_name='Healthy Rate')\n",
    "    plot_boxplot_with_dunn(df, 'Care_Index', group_col='abuse', yaxis_name='Care Index')\n",
    "    print()\n",
    "    \n",
    "    print(\"6.2 Creating Dentition Type Pairwise Plot...\")\n",
    "    plot_boxplot_by_dentition_type(df, output_dir)\n",
    "    print()\n",
    "    \n",
    "    print(\"7. Generating summary report...\")\n",
    "    generate_summary_report(df, table3_overall, output_dir, timestamp)\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Analysis Complete!\")\n",
    "    print(f\"All outputs saved to: {output_dir}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return df, table1, table2_cont, table2_cat, table3_overall, table3_posthoc, table4\n",
    "\n",
    "\n",
    "def generate_summary_report(df, table3_overall, output_dir, timestamp):\n",
    "    \"\"\"\n",
    "    解析結果のサマリーレポートを生成\n",
    "    \"\"\"\n",
    "    abuse_types = df['abuse'].cat.categories\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"=\" * 70)\n",
    "    report.append(\"SUMMARY REPORT: Oral Health by Abuse Type\")\n",
    "    report.append(\"=\" * 70)\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"1. SAMPLE SIZES\")\n",
    "    report.append(\"-\" * 40)\n",
    "    for abuse in abuse_types:\n",
    "        n = len(df[df['abuse'] == abuse])\n",
    "        report.append(f\"   {abuse}: n = {n}\")\n",
    "    report.append(f\"   Total: n = {len(df)}\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"2. KEY FINDINGS (Significant at p < 0.05)\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    if not table3_overall.empty:\n",
    "        sig_results = table3_overall[table3_overall['Significant'] == 'Yes']\n",
    "        if len(sig_results) > 0:\n",
    "            for _, row in sig_results.iterrows():\n",
    "                report.append(f\"   • {row['Variable']}: p = {row['p-value']}\")\n",
    "        else:\n",
    "            report.append(\"   No significant differences found.\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"3. DMFT INDEX BY ABUSE TYPE\")\n",
    "    report.append(\"-\" * 40)\n",
    "    if 'DMFT_Index' in df.columns:\n",
    "        for abuse in abuse_types:\n",
    "            subset = df[df['abuse'] == abuse]['DMFT_Index'].dropna()\n",
    "            if len(subset) > 0:\n",
    "                report.append(f\"   {abuse}:\")\n",
    "                report.append(f\"      Mean ± SD: {subset.mean():.2f} ± {subset.std():.2f}\")\n",
    "                report.append(f\"      Median [IQR]: {subset.median():.1f} [{subset.quantile(0.25):.1f}-{subset.quantile(0.75):.1f}]\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report_text = \"\\n\".join(report)\n",
    "    with open(f'{output_dir}summary_report_{timestamp}.txt', 'w') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(report_text)\n",
    "    print(f\"   ✓ Saved: summary_report_{timestamp}.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11713047",
   "metadata": {},
   "source": [
    "### メイン実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c222efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_complete_analysis(f'{INPUT_DIR}/data_OnlyAbuse_N1235.csv', OUTPUT_DIR, timestamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
