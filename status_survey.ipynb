{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/3dnb813d3ld83hg56j5wbw2w0000gn/T/ipykernel_35536/1347871611.py:162: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  n = df.groupby(group_cols, dropna=False).size().rename(\"n\").reset_index()\n",
      "/var/folders/nc/3dnb813d3ld83hg56j5wbw2w0000gn/T/ipykernel_35536/1347871611.py:165: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  perm_any = (df.groupby(group_cols, dropna=False)[\"Perm_DMF_any\"]\n",
      "/var/folders/nc/3dnb813d3ld83hg56j5wbw2w0000gn/T/ipykernel_35536/1347871611.py:168: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  perm_refD = (df.groupby(group_cols, dropna=False)[\"Perm_D_any\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot setitem on a Categorical with a new category (0), set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 328\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 279\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m grp_single   \u001b[38;5;241m=\u001b[39m [SEX_COL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage_single\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# 人数・割合・処置状況\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m tab_perm_agegroup, tab_baby_agegroup, n_agegroup \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_counts_and_rates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrp_agegroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m tab_perm_single,   tab_baby_single,   n_single   \u001b[38;5;241m=\u001b[39m summarize_counts_and_rates(df, grp_single)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# 平均・SD\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 172\u001b[0m, in \u001b[0;36msummarize_counts_and_rates\u001b[0;34m(df, group_cols)\u001b[0m\n\u001b[1;32m    165\u001b[0m perm_any \u001b[38;5;241m=\u001b[39m (df\u001b[38;5;241m.\u001b[39mgroupby(group_cols, dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerm_DMF_any\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    166\u001b[0m               \u001b[38;5;241m.\u001b[39magg(no_DMF\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[38;5;241m~\u001b[39mx)\u001b[38;5;241m.\u001b[39msum(), with_DMF\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m    167\u001b[0m               \u001b[38;5;241m.\u001b[39mreset_index())\n\u001b[1;32m    168\u001b[0m perm_refD \u001b[38;5;241m=\u001b[39m (df\u001b[38;5;241m.\u001b[39mgroupby(group_cols, dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerm_D_any\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    169\u001b[0m                \u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m                \u001b[38;5;241m.\u001b[39mreset_index())\n\u001b[0;32m--> 172\u001b[0m tab_perm \u001b[38;5;241m=\u001b[39m \u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm_any\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm_refD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m tab_perm \u001b[38;5;241m=\u001b[39m make_n_pct(tab_perm, n_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# 乳歯：dfあり/なし、処置状況（df>0のみ）\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:7434\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   7432\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m   7433\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7434\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[1;32m   7436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   7438\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotna(), value)\u001b[38;5;241m.\u001b[39m_mgr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/base.py:186\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2334\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[0m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2334\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2338\u001b[0m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray.fillna added a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2345\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   2346\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py:376\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[1;32m    379\u001b[0m         new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1589\u001b[0m, in \u001b[0;36mCategorical._validate_setitem_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_listlike(value)\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1614\u001b[0m, in \u001b[0;36mCategorical._validate_scalar\u001b[0;34m(self, fill_value)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbox_scalar(fill_value)\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot setitem on a Categorical with a new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfill_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), set the categories first\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1617\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fill_value\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot setitem on a Categorical with a new category (0), set the categories first"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 0) 入力・列名設定\n",
    "# =========================\n",
    "INPUT_PATH = \"/Users/ayo/Desktop/_GSAIS_/Research/OralHealth_tokyo/paper_analysis/data/AllData_tillMar2024.csv\"   # .csv でもOK\n",
    "\n",
    "ID_COL  = \"No_All\"\n",
    "AGE_COL = \"age\"\n",
    "SEX_COL = \"sex\"   # \"男/女\" or \"M/F\" など\n",
    "\n",
    "\n",
    "# 永久歯・乳歯の列（あなた指定）\n",
    "perm_cols = [\n",
    "    'U17', 'U16', 'U15', 'U14', 'U13', 'U12', 'U11', 'U21', 'U22', 'U23', 'U24', 'U25', 'U26', 'U27',\n",
    "    'L37', 'L36', 'L35', 'L34', 'L33', 'L32', 'L31', 'L41', 'L42', 'L43', 'L44', 'L45', 'L46', 'L47'\n",
    "]\n",
    "baby_cols = [\n",
    "    'u55', 'u54', 'u53', 'u52', 'u51', 'u61', 'u62', 'u63', 'u64', 'u65',\n",
    "    'l75', 'l74', 'l73', 'l72', 'l71', 'l81', 'l82', 'l83', 'l84', 'l85'\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 1) あなたの歯コード定義（固定）\n",
    "# =========================\n",
    "CODE_TREATED = 1   # 処置\n",
    "CODE_C0      = 2   # 要観察歯\n",
    "CODE_CARIES  = 3   # C（未処置）\n",
    "CODE_MISSING = 4   # 喪失\n",
    "CODE_TRAUMA  = 7   # 外傷\n",
    "CODE_RDT     = 8   # 残根（未処置扱い）\n",
    "\n",
    "# D/d には 3 と 8 を含める（あなたの定義）\n",
    "DECAY_SET = {CODE_CARIES, CODE_RDT}\n",
    "\n",
    "# =========================\n",
    "# 2) 年齢範囲と年齢階級\n",
    "# =========================\n",
    "AGE_MIN, AGE_MAX = 2, 17\n",
    "AGE_BINS   = [2, 6, 12, 18]                 # [2-5], [6-11], [12-17]\n",
    "AGE_LABELS = [\"2-5\", \"6-11\", \"12-17\"]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utility\n",
    "# =========================\n",
    "def read_input(path, sheet=None):\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        return pd.read_csv(path)\n",
    "    return pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "def ensure_cols_exist(df, cols, label):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{label}] columns not found: {missing}\")\n",
    "\n",
    "def standardize_sex(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"m\", \"male\", \"男\", \"1\"}:\n",
    "        return \"Male\"\n",
    "    if s in {\"f\", \"female\", \"女\", \"2\"}:\n",
    "        return \"Female\"\n",
    "    return str(x)\n",
    "\n",
    "def to_numeric_teeth(df, cols):\n",
    "    # 歯コードを数値化（文字の\"3\"等も吸収）\n",
    "    out = df.copy()\n",
    "    out[cols] = out[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "def safe_mean_sd(series):\n",
    "    x = pd.to_numeric(series, errors=\"coerce\")\n",
    "    return pd.Series({\"mean\": x.mean(skipna=True), \"sd\": x.std(skipna=True)})\n",
    "\n",
    "def add_age_groups(df):\n",
    "    df = df.copy()\n",
    "    df[AGE_COL] = pd.to_numeric(df[AGE_COL], errors=\"coerce\")\n",
    "    df = df[(df[AGE_COL] >= AGE_MIN) & (df[AGE_COL] <= AGE_MAX)].copy()\n",
    "    df[\"age_single\"] = df[AGE_COL].round().astype(\"Int64\")\n",
    "    df[\"age_group\"] = pd.cut(df[AGE_COL], bins=AGE_BINS, right=False, labels=AGE_LABELS)\n",
    "    return df\n",
    "\n",
    "def classify_df_treatment(d, f):\n",
    "    # df>0の人の処置状況（実態調査系）\n",
    "    if d == 0 and f > 0:\n",
    "        return \"Completely treated\"\n",
    "    if d > 0 and f > 0:\n",
    "        return \"Partially treated\"\n",
    "    if d > 0 and f == 0:\n",
    "        return \"Untreated\"\n",
    "    return \"No df\"\n",
    "\n",
    "def make_n_pct(tab, n_col=\"n\"):\n",
    "    out = tab.copy()\n",
    "    for c in out.columns:\n",
    "        if c == n_col:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(out[c]):\n",
    "            out[f\"{c}_pct\"] = out[c] / out[n_col] * 100\n",
    "    return out\n",
    "\n",
    "def per_row_count(df, cols, code_or_set):\n",
    "    sub = df[cols]\n",
    "    if isinstance(code_or_set, set):\n",
    "        return sub.isin(code_or_set).sum(axis=1)\n",
    "    else:\n",
    "        return (sub == code_or_set).sum(axis=1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 個人指標の作成（あなたの定義に準拠）\n",
    "# =========================\n",
    "def build_individual_indices(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 永久歯\n",
    "    df[\"Perm_D\"] = per_row_count(df, perm_cols, DECAY_SET)        # 3 or 8\n",
    "    df[\"Perm_M\"] = per_row_count(df, perm_cols, CODE_MISSING)     # 4\n",
    "    df[\"Perm_F\"] = per_row_count(df, perm_cols, CODE_TREATED)     # 1\n",
    "    df[\"Perm_DMFT\"] = df[\"Perm_D\"] + df[\"Perm_M\"] + df[\"Perm_F\"]\n",
    "\n",
    "    df[\"Perm_C0\"] = per_row_count(df, perm_cols, CODE_C0)         # 2\n",
    "    df[\"Perm_DMFT_C0\"] = df[\"Perm_DMFT\"] + df[\"Perm_C0\"]\n",
    "\n",
    "    # 乳歯\n",
    "    df[\"Baby_d\"] = per_row_count(df, baby_cols, DECAY_SET)        # 3 or 8\n",
    "    df[\"Baby_m\"] = per_row_count(df, baby_cols, CODE_MISSING)     # 4\n",
    "    df[\"Baby_f\"] = per_row_count(df, baby_cols, CODE_TREATED)     # 1\n",
    "    # ユーザー定義では Baby_DMFT という名前で d+m+f を作っているので合わせる\n",
    "    df[\"Baby_DMFT\"] = df[\"Baby_d\"] + df[\"Baby_m\"] + df[\"Baby_f\"]\n",
    "\n",
    "    df[\"Baby_C0\"] = per_row_count(df, baby_cols, CODE_C0)         # 2\n",
    "    df[\"Baby_DMFT_C0\"] = df[\"Baby_DMFT\"] + df[\"Baby_C0\"]\n",
    "\n",
    "    # 全歯（永久+乳歯）での追加カウント\n",
    "    all_cols = perm_cols + baby_cols\n",
    "    df[\"count_C0_all\"] = per_row_count(df, all_cols, CODE_C0)         # 2\n",
    "    df[\"count_Trauma_all\"] = per_row_count(df, all_cols, CODE_TRAUMA) # 7\n",
    "    df[\"count_RDT_all\"] = per_row_count(df, all_cols, CODE_RDT)       # 8\n",
    "\n",
    "    # 参考：う蝕経験の有無\n",
    "    df[\"Perm_DMF_any\"] = df[\"Perm_DMFT\"] > 0\n",
    "    df[\"Perm_D_any\"]   = df[\"Perm_D\"] > 0\n",
    "    df[\"Baby_df_any\"]  = (df[\"Baby_d\"] + df[\"Baby_f\"]) > 0   # 乳歯は df（m除外）を処置状況に使うことが多い\n",
    "    df[\"Baby_d_any\"]   = df[\"Baby_d\"] > 0\n",
    "\n",
    "    # 乳歯の「処置状況」（df>0対象）\n",
    "    df[\"Baby_df_status\"] = df.apply(lambda r: classify_df_treatment(int(r[\"Baby_d\"]), int(r[\"Baby_f\"])), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 集計表（実態調査風）\n",
    "# =========================\n",
    "def summarize_counts_and_rates(df, group_cols):\n",
    "    # 被調査者数\n",
    "    n = df.groupby(group_cols, dropna=False).size().rename(\"n\").reset_index()\n",
    "\n",
    "    # 永久歯：DMFあり/なし、（参考）Dあり\n",
    "    perm_any = (df.groupby(group_cols, dropna=False)[\"Perm_DMF_any\"]\n",
    "                  .agg(no_DMF=lambda x: (~x).sum(), with_DMF=lambda x: x.sum())\n",
    "                  .reset_index())\n",
    "    perm_refD = (df.groupby(group_cols, dropna=False)[\"Perm_D_any\"]\n",
    "                   .sum().rename(\"with_D\")\n",
    "                   .reset_index())\n",
    "\n",
    "    tab_perm = n.merge(perm_any, on=group_cols, how=\"left\").merge(perm_refD, on=group_cols, how=\"left\").fillna(0)\n",
    "    tab_perm = make_n_pct(tab_perm, n_col=\"n\")\n",
    "\n",
    "    # 乳歯：dfあり/なし、処置状況（df>0のみ）\n",
    "    baby_any = (df.groupby(group_cols, dropna=False)[\"Baby_df_any\"]\n",
    "                  .agg(no_df=lambda x: (~x).sum(), with_df=lambda x: x.sum())\n",
    "                  .reset_index())\n",
    "    baby_status = (df[df[\"Baby_df_any\"]]\n",
    "                   .groupby(group_cols, dropna=False)[\"Baby_df_status\"]\n",
    "                   .value_counts()\n",
    "                   .unstack(fill_value=0)\n",
    "                   .reset_index())\n",
    "\n",
    "    tab_baby = n.merge(baby_any, on=group_cols, how=\"left\").merge(baby_status, on=group_cols, how=\"left\").fillna(0)\n",
    "    tab_baby = make_n_pct(tab_baby, n_col=\"n\")\n",
    "\n",
    "    return tab_perm, tab_baby, n\n",
    "\n",
    "def summarize_mean_sd(df, group_cols):\n",
    "    # 平均（SD）—永久歯\n",
    "    perm_vars = [\"Perm_D\",\"Perm_M\",\"Perm_F\",\"Perm_DMFT\",\"Perm_C0\",\"Perm_DMFT_C0\"]\n",
    "    baby_vars = [\"Baby_d\",\"Baby_m\",\"Baby_f\",\"Baby_DMFT\",\"Baby_C0\",\"Baby_DMFT_C0\"]\n",
    "    other_vars = [\"count_C0_all\",\"count_Trauma_all\",\"count_RDT_all\"]\n",
    "\n",
    "    perm = (df.groupby(group_cols, dropna=False)[perm_vars]\n",
    "            .agg([\"mean\",\"std\"]).reset_index())\n",
    "    perm.columns = [\"_\".join([c for c in col if c]) if isinstance(col, tuple) else col for col in perm.columns]\n",
    "\n",
    "    baby = (df.groupby(group_cols, dropna=False)[baby_vars]\n",
    "            .agg([\"mean\",\"std\"]).reset_index())\n",
    "    baby.columns = [\"_\".join([c for c in col if c]) if isinstance(col, tuple) else col for col in baby.columns]\n",
    "\n",
    "    other = (df.groupby(group_cols, dropna=False)[other_vars]\n",
    "             .agg([\"mean\",\"std\"]).reset_index())\n",
    "    other.columns = [\"_\".join([c for c in col if c]) if isinstance(col, tuple) else col for col in other.columns]\n",
    "\n",
    "    return perm, baby, other\n",
    "\n",
    "def tooth_code_distribution(df, tooth_cols, group_cols, dataset_label):\n",
    "    \"\"\"\n",
    "    表14系：歯別×コードの分布（コード=1/2/3/4/7/8/その他）\n",
    "    \"\"\"\n",
    "    tmp = df[[ID_COL] + group_cols + tooth_cols].copy()\n",
    "    long = tmp.melt(id_vars=[ID_COL] + group_cols, var_name=\"tooth\", value_name=\"code\")\n",
    "    # 欠損も含めた分布が欲しい場合は dropna=False を活用\n",
    "    dist = (long.groupby(group_cols + [\"tooth\", \"code\"], dropna=False)\n",
    "            .size().rename(\"count\").reset_index())\n",
    "    dist[\"dataset\"] = dataset_label\n",
    "    return dist\n",
    "\n",
    "def tooth_category_distribution(df, tooth_cols, group_cols, dataset_label):\n",
    "    \"\"\"\n",
    "    表14を「コード」ではなく「カテゴリ（Treated/C0/Decayed/Missing/Trauma/Other/NA）」で出す版\n",
    "    \"\"\"\n",
    "    tmp = df[[ID_COL] + group_cols + tooth_cols].copy()\n",
    "    long = tmp.melt(id_vars=[ID_COL] + group_cols, var_name=\"tooth\", value_name=\"code\")\n",
    "\n",
    "    def cat(x):\n",
    "        if pd.isna(x):\n",
    "            return \"NA\"\n",
    "        if x == CODE_TREATED:\n",
    "            return \"Treated(1)\"\n",
    "        if x == CODE_C0:\n",
    "            return \"C0(2)\"\n",
    "        if x in DECAY_SET:\n",
    "            # 3 or 8 を分けたいならここを拡張\n",
    "            return \"Decayed_or_RDT(3/8)\"\n",
    "        if x == CODE_MISSING:\n",
    "            return \"Missing(4)\"\n",
    "        if x == CODE_TRAUMA:\n",
    "            return \"Trauma(7)\"\n",
    "        return \"Other\"\n",
    "\n",
    "    long[\"category\"] = long[\"code\"].apply(cat)\n",
    "    dist = (long.groupby(group_cols + [\"tooth\", \"category\"], dropna=False)\n",
    "            .size().rename(\"count\").reset_index())\n",
    "    dist[\"dataset\"] = dataset_label\n",
    "    return dist\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    df = read_input(INPUT_PATH, SHEET_NAME)\n",
    "    df = df.copy()\n",
    "\n",
    "    # 列チェック\n",
    "    for c in [ID_COL, AGE_COL, SEX_COL]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Required column not found: {c}\")\n",
    "    ensure_cols_exist(df, perm_cols, \"perm_cols\")\n",
    "    ensure_cols_exist(df, baby_cols, \"baby_cols\")\n",
    "\n",
    "    # 前処理：性の標準化、歯コードの数値化、年齢範囲/階級\n",
    "    df[SEX_COL] = df[SEX_COL].apply(standardize_sex)\n",
    "    df = to_numeric_teeth(df, perm_cols + baby_cols)\n",
    "    df = add_age_groups(df)\n",
    "\n",
    "    # 個人指標を付与\n",
    "    df = build_individual_indices(df)\n",
    "\n",
    "    # グループ（実態調査っぽく：性×年齢階級 と 性×単歳）\n",
    "    grp_agegroup = [SEX_COL, \"age_group\"]\n",
    "    grp_single   = [SEX_COL, \"age_single\"]\n",
    "\n",
    "    # 人数・割合・処置状況\n",
    "    tab_perm_agegroup, tab_baby_agegroup, n_agegroup = summarize_counts_and_rates(df, grp_agegroup)\n",
    "    tab_perm_single,   tab_baby_single,   n_single   = summarize_counts_and_rates(df, grp_single)\n",
    "\n",
    "    # 平均・SD\n",
    "    mean_perm_agegroup, mean_baby_agegroup, mean_other_agegroup = summarize_mean_sd(df, grp_agegroup)\n",
    "    mean_perm_single,   mean_baby_single,   mean_other_single   = summarize_mean_sd(df, grp_single)\n",
    "\n",
    "    # 歯別分布（コード版とカテゴリ版）\n",
    "    dist_perm_code = tooth_code_distribution(df, perm_cols, grp_agegroup, \"permanent\")\n",
    "    dist_baby_code = tooth_code_distribution(df, baby_cols, grp_agegroup, \"baby\")\n",
    "    dist_perm_cat  = tooth_category_distribution(df, perm_cols, grp_agegroup, \"permanent\")\n",
    "    dist_baby_cat  = tooth_category_distribution(df, baby_cols, grp_agegroup, \"baby\")\n",
    "\n",
    "    # 出力\n",
    "    out_path = \"output_tables.xlsx\"\n",
    "    with pd.ExcelWriter(out_path, engine=\"openpyxl\") as w:\n",
    "        # 被調査者数\n",
    "        n_agegroup.to_excel(w, sheet_name=\"1_n_agegroup\", index=False)\n",
    "        n_single.to_excel(w,   sheet_name=\"1_n_single\",   index=False)\n",
    "\n",
    "        # 永久歯：DMF有無（表10系）\n",
    "        tab_perm_agegroup.to_excel(w, sheet_name=\"10_perm_DMF_any_agegroup\", index=False)\n",
    "        tab_perm_single.to_excel(w,   sheet_name=\"10_perm_DMF_any_single\",   index=False)\n",
    "\n",
    "        # 乳歯：df有無＋処置状況（表8系）\n",
    "        tab_baby_agegroup.to_excel(w, sheet_name=\"8_baby_df_status_agegroup\", index=False)\n",
    "        tab_baby_single.to_excel(w,   sheet_name=\"8_baby_df_status_single\",   index=False)\n",
    "\n",
    "        # 平均・SD（表13系＋C0込み指標）\n",
    "        mean_perm_agegroup.to_excel(w, sheet_name=\"13_perm_mean_sd_agegroup\", index=False)\n",
    "        mean_baby_agegroup.to_excel(w, sheet_name=\"13_baby_mean_sd_agegroup\", index=False)\n",
    "        mean_other_agegroup.to_excel(w, sheet_name=\"13_other_mean_sd_agegroup\", index=False)\n",
    "\n",
    "        mean_perm_single.to_excel(w, sheet_name=\"13_perm_mean_sd_single\", index=False)\n",
    "        mean_baby_single.to_excel(w, sheet_name=\"13_baby_mean_sd_single\", index=False)\n",
    "        mean_other_single.to_excel(w, sheet_name=\"13_other_mean_sd_single\", index=False)\n",
    "\n",
    "        # 歯別分布（表14系）\n",
    "        dist_perm_code.to_excel(w, sheet_name=\"14_perm_tooth_code_dist\", index=False)\n",
    "        dist_baby_code.to_excel(w, sheet_name=\"14_baby_tooth_code_dist\", index=False)\n",
    "        dist_perm_cat.to_excel(w,  sheet_name=\"14_perm_tooth_cat_dist\", index=False)\n",
    "        dist_baby_cat.to_excel(w,  sheet_name=\"14_baby_tooth_cat_dist\", index=False)\n",
    "\n",
    "        # 個票（確認用：必要ならコメントアウト）\n",
    "        df.to_excel(w, sheet_name=\"0_individual_with_indices\", index=False)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
